{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c70460-ab91-405b-9e43-2caeda8e9c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from os import listdir, path\n",
    "from os.path import isfile, join\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes \n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d99685-e7e2-46c0-acd2-1c66313c43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_list = ['mnist','blog','income','cifar10']\n",
    "dataset_list = ['aloi','blog','adult','syn','sensorless','covtype','helena','higgs_small']\n",
    "# dataset_list = ['syn','cifar10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f01ffe1-e2c0-4f77-b1c6-7ce90c4c0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles=[]\n",
    "for dataset in dataset_list :\n",
    "    mypath = \"results/\"+ dataset +\"/\"\n",
    "    onlyfiles = [mypath + f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    onlyfiles = [f for f in onlyfiles if f[-3:] == \"csv\"]\n",
    "    allFiles.extend(onlyfiles)\n",
    "# allFiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c8088c-2323-4f57-9a76-355a14ef1e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/aloi/Client-1-contrastive-50e-6fl-0.5mc-scale_at-0.5rl-aloi.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "227a3ace-a9a0-464c-8d63-64bdf192046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(allFiles):\n",
    "    dt = pd.read_csv(item)\n",
    "    dt[\"client\"] = int(item.split(\"-\")[1])\n",
    "    # dt[\"type\"] = item.split(\"-\")[-1].split(\".\")[0]\n",
    "    dt[\"epoch\"] = int(item.split(\"-\")[3][:-1])\n",
    "    dt[\"fl\"] = int(item.split(\"-\")[4][:-2])\n",
    "    dt[\"mc\"] = float(item.split(\"-\")[5][:-2])\n",
    "    dt[\"at\"] = str(item.split(\"-\")[6][:-3])\n",
    "    dt[\"rl\"] = float(item.split(\"-\")[7][:-2])\n",
    "    dt[\"db\"] = str(item.split(\"-\")[8][:-4])\n",
    "    dt[\"f1\"] = dt.test_acc.apply(lambda x : eval(x)[-2])\n",
    "    dt[\"accuracy\"] = dt.test_acc.apply(lambda x : eval(x)[0])\n",
    "    \n",
    "    if i ==0 : db = dt\n",
    "    else : db = pd.concat([db,dt])\n",
    "# db = pd.merge(db[db.type == 'original'], db[db.type == 'contrastive'], on=[\"client\",\"model\"])\n",
    "db = db[['client',\t'epoch',\t'fl',\t'mc',\t'at',\t'rl',\t'db','accuracy','f1']]\n",
    "db = db[db.epoch == 50]\n",
    "# db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a76e543-c307-4fff-94fe-7da7056c55bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aloi', 'blog', 'adult', 'syn', 'sensorless', 'covtype', 'helena',\n",
       "       'higgs_small'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.db.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e6a8b4-ba1d-4fc3-a808-9ab2c266e700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['combined'] = db[[  'mc', 'rl']].apply(\n",
    "    lambda x: '_'.join(x.astype(str)), axis=1\n",
    ")\n",
    "idx = [x+ '_' +item+'_'+str(n) for n in range(6) for item in db['at'].unique() for x in db.sort_values(['mc','rl'])['combined'].unique()]\n",
    "idx = pd.DataFrame(idx, columns=['idx'])\n",
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd0fc95-8121-4cb5-af6c-b200501cf945",
   "metadata": {},
   "outputs": [],
   "source": [
    "db['combined'] = db[[  'mc', 'rl','at','client']].apply(\n",
    "    lambda x: '_'.join(x.astype(str)), axis=1\n",
    ")\n",
    "# db['combined']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e270d345-40ee-41c1-b0e7-3398830de568",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a611cf8-f534-4c33-87d2-7ad7fcc97356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset used: helena\n",
      "***Fail Matrix***\n",
      "at    mc    rl  ascent  replacement  scale  targeted\n",
      "0   0.00  1.00     NaN          NaN    0.0       NaN\n",
      "1   0.25  0.25     0.0          0.0    0.0       0.0\n",
      "2   0.25  0.50     0.0          0.0    0.0       0.0\n",
      "3   0.25  0.75     0.0          0.0    0.0       0.0\n",
      "4   0.25  1.00     0.0          0.0    0.0       0.0\n",
      "5   0.50  0.25     6.0          0.0    0.0       0.0\n",
      "6   0.50  0.50     6.0          0.0    0.0       0.0\n",
      "7   0.50  0.75     6.0          0.0    0.0       0.0\n",
      "8   0.50  1.00     6.0          0.0    0.0       0.0\n",
      "9   0.75  0.25     6.0          0.0    0.0       0.0\n",
      "10  0.75  0.50     6.0          0.0    0.0       0.0\n",
      "11  0.75  0.75     6.0          0.0    0.0       0.0\n",
      "12  0.75  1.00     6.0          0.0    0.0       0.0\n",
      "at    replacement  scale  targeted\n",
      "mc                                \n",
      "0.00          0.0    0.0       0.0\n",
      "0.25          0.0    0.0       0.0\n",
      "0.50          0.0    0.0       0.0\n",
      "0.75          0.0    0.0       0.0\n",
      "at    replacement  scale  targeted\n",
      "rl                                \n",
      "0.25          0.0    0.0       0.0\n",
      "0.50          0.0    0.0       0.0\n",
      "0.75          0.0    0.0       0.0\n",
      "1.00          0.0    0.0       0.0\n",
      "***F1 Matrix***\n",
      "at    mc    rl    ascent  replacement     scale  targeted\n",
      "0   0.00  1.00       NaN          NaN  0.137967       NaN\n",
      "1   0.25  0.25  0.127948     0.131999  0.009383  0.131999\n",
      "2   0.25  0.50  0.122169     0.129934  0.009383  0.129934\n",
      "3   0.25  0.75  0.118146     0.133816  0.009383  0.133816\n",
      "4   0.25  1.00  0.116506     0.137967  0.009383  0.137967\n",
      "5   0.50  0.25       NaN     0.136945  0.009383  0.136945\n",
      "6   0.50  0.50       NaN     0.133677  0.009383  0.133677\n",
      "7   0.50  0.75       NaN     0.134819  0.009383  0.134819\n",
      "8   0.50  1.00       NaN     0.137967  0.009383  0.137967\n",
      "9   0.75  0.25       NaN     0.132532  0.009383  0.132532\n",
      "10  0.75  0.50       NaN     0.129919  0.009383  0.129919\n",
      "11  0.75  0.75       NaN     0.134368  0.009383  0.134368\n",
      "12  0.75  1.00       NaN     0.137967  0.009383  0.137967\n",
      "at    replacement     scale  targeted\n",
      "mc                                   \n",
      "0.00          NaN  0.137967       NaN\n",
      "0.25     0.133429  0.009383  0.133429\n",
      "0.50     0.135852  0.009383  0.135852\n",
      "0.75     0.133696  0.009383  0.133696\n",
      "at    replacement     scale  targeted\n",
      "rl                                   \n",
      "0.25     0.133825  0.009383  0.133825\n",
      "0.50     0.131177  0.009383  0.131177\n",
      "0.75     0.134334  0.009383  0.134334\n",
      "1.00     0.137967  0.041529  0.137967\n",
      "***End of Matrixs***\n"
     ]
    }
   ],
   "source": [
    "def printDb(dataset):\n",
    "# dataset = 'aloi'\n",
    "    print('Dataset used:', dataset)\n",
    "    dbAloi = db[db['db'] == dataset]\n",
    "    dbx = idx.merge(dbAloi,left_on='idx', \n",
    "                          right_on='combined',\n",
    "                          how='left')\n",
    "    dbx = dbx[['idx','client', 'mc', 'at', 'rl', 'db', 'accuracy',\n",
    "           'f1',]]\n",
    "    # dbx.isna()\n",
    "    # dbx.idx.apply(lambda x : x.split('_'))\n",
    "    dbx.client = dbx.idx.apply(lambda x : x.split('_')[-1])\n",
    "    dbx.mc = dbx.idx.apply(lambda x : x.split('_')[0])\n",
    "    dbx.rl = dbx.idx.apply(lambda x : x.split('_')[1])\n",
    "    dbx['at'] = dbx.idx.apply(lambda x : x.split('_')[-2])\n",
    "    dbx['nl'] = dbx.f1.isna()\n",
    "    dbx['nnl'] = dbx.f1.notna()\n",
    "    \n",
    "    dbx['db'] = dataset\n",
    "    dbx = dbx.drop(\n",
    "        dbx.query(\"mc == '0.0' and at!= 'scale'\").index\n",
    "    )\n",
    "    # dbx[['mc','rl','at','f1','accuracy']].groupby(['mc','rl','at'])[['f1','accuracy']].apply(lambda x: x.isna().sum())\n",
    "    dbNl = dbx[['mc','rl','at','nl']].pivot_table(\n",
    "                    values='nl', \n",
    "                    index=['mc','rl',],\n",
    "                    columns='at',\n",
    "                    aggfunc='sum').reset_index().astype('float')\n",
    "    print('***Fail Matrix***')\n",
    "    print(dbNl)\n",
    "    print(dbNl[['mc','replacement','scale','targeted']].groupby('mc').sum()/24)\n",
    "    print(dbNl[['rl','replacement','scale','targeted']].groupby('rl').sum() / 24)\n",
    "    # dbNnl = \n",
    "    dbx.f1 = dbx.f1.apply(lambda x : x if x>0 else np.nan)\n",
    "    dbF1 = dbx[['mc','rl','at','f1']].pivot_table(\n",
    "                    values='f1', \n",
    "                    index=['mc','rl',],\n",
    "                    columns='at',\n",
    "                    aggfunc='mean').reset_index().astype('float')\n",
    "    print('***F1 Matrix***')\n",
    "    print(dbF1)\n",
    "    print(dbF1[['mc','replacement','scale','targeted']].groupby('mc').mean())\n",
    "    print(dbF1[['rl','replacement','scale','targeted']].groupby('rl').mean())\n",
    "    print('***End of Matrixs***')\n",
    "\n",
    "\n",
    "printDb('helena')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a5f4cf5-a435-42c8-b786-2b577b8d1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in dataset_list:\n",
    "#     printDb(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f959ede-d4be-442a-a1a2-212be02e387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def printDb(dataset): \n",
    "dataset = 'aloi'\n",
    "print('Dataset used:', dataset)\n",
    "dbAloi = db[db['db'] == dataset]\n",
    "dbx = idx.merge(dbAloi,left_on='idx', \n",
    "                      right_on='combined',\n",
    "                      how='left')\n",
    "dbx = dbx[['idx','client', 'mc', 'at', 'rl', 'db', 'accuracy',\n",
    "       'f1',]]\n",
    "# dbx.isna()\n",
    "# dbx.idx.apply(lambda x : x.split('_'))\n",
    "dbx.client = dbx.idx.apply(lambda x : x.split('_')[-1])\n",
    "dbx.mc = dbx.idx.apply(lambda x : x.split('_')[0])\n",
    "dbx.rl = dbx.idx.apply(lambda x : x.split('_')[1])\n",
    "dbx['at'] = dbx.idx.apply(lambda x : x.split('_')[-2])\n",
    "dbx['nl'] = dbx.f1.isna()\n",
    "dbx['nnl'] = dbx.f1.notna()\n",
    "\n",
    "dbx['db'] = dataset\n",
    "dbx = dbx.drop(\n",
    "    dbx.query(\"mc == '0.0' and at!= 'scale'\").index\n",
    ")\n",
    "# dbx[['mc','rl','at','f1','accuracy']].groupby(['mc','rl','at'])[['f1','accuracy']].apply(lambda x: x.isna().sum())\n",
    "dbNl = dbx[['mc','rl','at','nl']].pivot_table(\n",
    "                values='nl', \n",
    "                index=['mc','rl',],\n",
    "                columns='at',\n",
    "                aggfunc='sum').reset_index().astype('float')\n",
    "print('***Fail Matrix***')\n",
    "print(dbNl)\n",
    "print(dbNl[['mc','replacement','scale','targeted']].groupby('mc').sum()/24)\n",
    "print(dbNl[['rl','replacement','scale','targeted']].groupby('rl').sum() / 24)\n",
    "# dbNnl = \n",
    "dbx.f1 = dbx.f1.apply(lambda x : x if x>0 else np.nan)\n",
    "dbF1 = dbx[['mc','rl','at','f1']].pivot_table(\n",
    "                values='f1', \n",
    "                index=['mc','rl',],\n",
    "                columns='at',\n",
    "                aggfunc='mean').reset_index().astype('float')\n",
    "print('***F1 Matrix***')\n",
    "print(dbF1)\n",
    "print(dbF1[['mc','replacement','scale','targeted']].groupby('mc').mean())\n",
    "print(dbF1[['rl','replacement','scale','targeted']].groupby('rl').mean())\n",
    "print('***End of Matrixs***')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b32c4830-9fdd-4e24-bb90-d7afc3fb9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dx = db[(db.client_drop>0)&(db.class_imbalance>0)]\\\n",
    "# [['model','test_acc', 'client', 'type', 'dataset']]\\\n",
    "# .pivot(index=['dataset','model','client'],\n",
    "#        values=['test_acc'],\n",
    "#        columns=['type'])\\\n",
    "# .reset_index()\n",
    "# dx.columns = ['dataset','model','client','fl','SubTab','local']\n",
    "# dx.set_index(['client','dataset'], inplace=True)\n",
    "# dx = dx[dx.model=='CFL'][['fl','local']].join(\n",
    "#     dx[dx.model=='LL'][['local']], rsuffix='_LL').join(\n",
    "#     dx[dx.model=='SubTab'][['SubTab']], rsuffix='_LL').join(\n",
    "#     dx[dx.model=='SubTab FL'][['SubTab']], rsuffix='_LL').reset_index()\n",
    "# dx.columns = ['client', 'dataset', 'CFL', 'C','LL','SubTab', 'SubtTab FL']\n",
    "# dx = dx[['client', 'dataset', 'CFL', 'C','LL','SubTab', 'SubtTab FL']]\n",
    "\n",
    "# (dx.groupby('dataset')[['CFL']].mean().style.highlight_min(color = 'red', axis = 1))\\\n",
    "# .highlight_max(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eafc1b8-2d53-4de7-b305-e18f8a22ff06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

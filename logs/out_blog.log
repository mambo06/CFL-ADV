Experiemnts on dataset: blog
python -W ignore adv_train.py -d blog -e 50 -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: []
Attack type: scale
Epoch 0, Loss: 20.6188
Epoch 1, Loss: 15.5862
Epoch 2, Loss: 14.7341
Epoch 3, Loss: 14.2666
Epoch 4, Loss: 14.7248
Epoch 5, Loss: 13.9848
Epoch 6, Loss: 13.9072
Epoch 7, Loss: 13.8302
Epoch 8, Loss: 13.8564
Epoch 9, Loss: 14.2936
Epoch 10, Loss: 13.7317
Epoch 11, Loss: 13.6823
Epoch 12, Loss: 13.5737
Epoch 13, Loss: 13.6060
Epoch 14, Loss: 13.5991
Epoch 15, Loss: 13.5049
Epoch 16, Loss: 13.4744
Epoch 17, Loss: 16.5504
Epoch 18, Loss: 14.5918
Epoch 19, Loss: 13.9492
Epoch 20, Loss: 13.6994
Epoch 21, Loss: 13.6371
Epoch 22, Loss: 13.5997
Epoch 23, Loss: 13.5730
Epoch 24, Loss: 13.4992
Epoch 25, Loss: 13.5103
Epoch 26, Loss: 13.4717
Epoch 27, Loss: 13.4201
Epoch 28, Loss: 13.4560
Epoch 29, Loss: 16.9804
Epoch 30, Loss: 14.6414
Epoch 31, Loss: 13.9289
Epoch 32, Loss: 13.7325
Epoch 33, Loss: 13.6456
Epoch 34, Loss: 13.5345
Epoch 35, Loss: 13.5106
Epoch 36, Loss: 13.4667
Epoch 37, Loss: 13.4590
Epoch 38, Loss: 13.4409
Epoch 39, Loss: 14.0533
Epoch 40, Loss: 13.6477
Epoch 41, Loss: 13.4955
Epoch 42, Loss: 13.4957
Epoch 43, Loss: 13.4752
Epoch 44, Loss: 13.4493
Epoch 45, Loss: 13.4498
Epoch 46, Loss: 15.2847
Epoch 47, Loss: 13.9806
Epoch 48, Loss: 13.5794
Epoch 49, Loss: 13.4640
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7235559379385614, recall 0.7568857152259041, F1 0.6776356583338788, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0mc-scale_at-1rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142615593426574, recall 0.8247992628669212, F1 0.8123165500837949, support None
Test score: precision 0.8045678416963299, recall 0.8163151140215209, F1 0.8029384222047992, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0mc-scale_at-1rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7625406215324322, recall 0.7699091746742135, F1 0.6982268978800537, support None
Test score: precision 0.7263253356092481, recall 0.758629767350028, F1 0.6847887168399717, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0mc-scale_at-1rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7470536559173719, recall 0.7739897327892589, F1 0.731222578497255, support None
Test score: precision 0.7408891549109808, recall 0.7692586133140281, F1 0.7246012294380897, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0mc-scale_at-1rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7303744388557554, recall 0.7646439383967355, F1 0.7221640138097073, support None
Test score: precision 0.7069823003826086, recall 0.7501398532363684, F1 0.7049701104576007, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0mc-scale_at-1rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7595223221508675, recall 0.7767613281121458, F1 0.7265284258530329, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0mc-scale_at-1rl-blog.csv
====================================================================================================

Mean results : 0.7202437605212287
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.25 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: scale
Epoch 0, Loss: 41.8304
Epoch 1, Loss: 39.4559
Epoch 2, Loss: 44.5540
Epoch 3, Loss: 94.3246
Epoch 4, Loss: 100.1074
Epoch 5, Loss: 100.1074
Epoch 6, Loss: 100.1074
Epoch 7, Loss: 100.1074
Epoch 8, Loss: 100.1074
Epoch 9, Loss: 100.1074
Epoch 10, Loss: 100.1074
Epoch 11, Loss: 100.1074
Epoch 12, Loss: 100.1074
Epoch 13, Loss: 100.1074
Epoch 14, Loss: 100.1074
Epoch 15, Loss: 100.1074
Epoch 16, Loss: 100.1074
Epoch 17, Loss: 100.1074
Epoch 18, Loss: 100.1074
Epoch 19, Loss: 100.1074
Epoch 20, Loss: 100.1074
Epoch 21, Loss: 100.1074
Epoch 22, Loss: 100.1074
Epoch 23, Loss: 100.1074
Epoch 24, Loss: 100.1074
Epoch 25, Loss: 100.1074
Epoch 26, Loss: 100.1074
Epoch 27, Loss: 100.1074
Epoch 28, Loss: 100.1074
Epoch 29, Loss: 100.1074
Epoch 30, Loss: 100.1074
Epoch 31, Loss: 100.1074
Epoch 32, Loss: 100.1074
Epoch 33, Loss: 100.1074
Epoch 34, Loss: 100.1074
Epoch 35, Loss: 100.1074
Epoch 36, Loss: 100.1074
Epoch 37, Loss: 100.1074
Epoch 38, Loss: 100.1074
Epoch 39, Loss: 100.1074
Epoch 40, Loss: 100.1074
Epoch 41, Loss: 100.1074
Epoch 42, Loss: 100.1074
Epoch 43, Loss: 100.1074
Epoch 44, Loss: 100.1074
Epoch 45, Loss: 100.1074
Epoch 46, Loss: 100.1074
Epoch 47, Loss: 100.1074
Epoch 48, Loss: 100.1074
Epoch 49, Loss: 100.1074
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-scale_at-1.0rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.25 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: model_replacement
Epoch 0, Loss: 20.6188
Epoch 1, Loss: 15.5862
Epoch 2, Loss: 14.7341
Epoch 3, Loss: 14.2666
Epoch 4, Loss: 14.7248
Epoch 5, Loss: 13.9848
Epoch 6, Loss: 13.9072
Epoch 7, Loss: 13.8302
Epoch 8, Loss: 13.8564
Epoch 9, Loss: 14.2936
Epoch 10, Loss: 13.7317
Epoch 11, Loss: 13.6823
Epoch 12, Loss: 13.5737
Epoch 13, Loss: 13.6060
Epoch 14, Loss: 13.5991
Epoch 15, Loss: 13.5049
Epoch 16, Loss: 13.4744
Epoch 17, Loss: 16.5504
Epoch 18, Loss: 14.5918
Epoch 19, Loss: 13.9492
Epoch 20, Loss: 13.6994
Epoch 21, Loss: 13.6371
Epoch 22, Loss: 13.5997
Epoch 23, Loss: 13.5730
Epoch 24, Loss: 13.4992
Epoch 25, Loss: 13.5103
Epoch 26, Loss: 13.4717
Epoch 27, Loss: 13.4201
Epoch 28, Loss: 13.4560
Epoch 29, Loss: 16.9804
Epoch 30, Loss: 14.6414
Epoch 31, Loss: 13.9289
Epoch 32, Loss: 13.7325
Epoch 33, Loss: 13.6456
Epoch 34, Loss: 13.5345
Epoch 35, Loss: 13.5106
Epoch 36, Loss: 13.4667
Epoch 37, Loss: 13.4590
Epoch 38, Loss: 13.4409
Epoch 39, Loss: 14.0533
Epoch 40, Loss: 13.6477
Epoch 41, Loss: 13.4955
Epoch 42, Loss: 13.4957
Epoch 43, Loss: 13.4752
Epoch 44, Loss: 13.4493
Epoch 45, Loss: 13.4498
Epoch 46, Loss: 15.2847
Epoch 47, Loss: 13.9806
Epoch 48, Loss: 13.5794
Epoch 49, Loss: 13.4640
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7235559379385614, recall 0.7568857152259041, F1 0.6776356583338788, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142615593426574, recall 0.8247992628669212, F1 0.8123165500837949, support None
Test score: precision 0.8045678416963299, recall 0.8163151140215209, F1 0.8029384222047992, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7625406215324322, recall 0.7699091746742135, F1 0.6982268978800537, support None
Test score: precision 0.7263253356092481, recall 0.758629767350028, F1 0.6847887168399717, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7470536559173719, recall 0.7739897327892589, F1 0.731222578497255, support None
Test score: precision 0.7408891549109808, recall 0.7692586133140281, F1 0.7246012294380897, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7303744388557554, recall 0.7646439383967355, F1 0.7221640138097073, support None
Test score: precision 0.7069823003826086, recall 0.7501398532363684, F1 0.7049701104576007, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7595223221508675, recall 0.7767613281121458, F1 0.7265284258530329, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Mean results : 0.7202437605212287
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.25 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.25 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: gradient_ascent
Epoch 0, Loss: 412.3383
Epoch 1, Loss: 144451051177510.5000
Epoch 2, Loss: 626053073456766518414016512.0000
Epoch 3, Loss: inf
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.25 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: targeted
Epoch 0, Loss: 20.6188
Epoch 1, Loss: 15.5862
Epoch 2, Loss: 14.7341
Epoch 3, Loss: 14.2666
Epoch 4, Loss: 14.7248
Epoch 5, Loss: 13.9848
Epoch 6, Loss: 13.9072
Epoch 7, Loss: 13.8302
Epoch 8, Loss: 13.8564
Epoch 9, Loss: 14.2936
Epoch 10, Loss: 13.7317
Epoch 11, Loss: 13.6823
Epoch 12, Loss: 13.5737
Epoch 13, Loss: 13.6060
Epoch 14, Loss: 13.5991
Epoch 15, Loss: 13.5049
Epoch 16, Loss: 13.4744
Epoch 17, Loss: 16.5504
Epoch 18, Loss: 14.5918
Epoch 19, Loss: 13.9492
Epoch 20, Loss: 13.6994
Epoch 21, Loss: 13.6371
Epoch 22, Loss: 13.5997
Epoch 23, Loss: 13.5730
Epoch 24, Loss: 13.4992
Epoch 25, Loss: 13.5103
Epoch 26, Loss: 13.4717
Epoch 27, Loss: 13.4201
Epoch 28, Loss: 13.4560
Epoch 29, Loss: 16.9804
Epoch 30, Loss: 14.6414
Epoch 31, Loss: 13.9289
Epoch 32, Loss: 13.7325
Epoch 33, Loss: 13.6456
Epoch 34, Loss: 13.5345
Epoch 35, Loss: 13.5106
Epoch 36, Loss: 13.4667
Epoch 37, Loss: 13.4590
Epoch 38, Loss: 13.4409
Epoch 39, Loss: 14.0533
Epoch 40, Loss: 13.6477
Epoch 41, Loss: 13.4955
Epoch 42, Loss: 13.4957
Epoch 43, Loss: 13.4752
Epoch 44, Loss: 13.4493
Epoch 45, Loss: 13.4498
Epoch 46, Loss: 15.2847
Epoch 47, Loss: 13.9806
Epoch 48, Loss: 13.5794
Epoch 49, Loss: 13.4640
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7235559379385614, recall 0.7568857152259041, F1 0.6776356583338788, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142615593426574, recall 0.8247992628669212, F1 0.8123165500837949, support None
Test score: precision 0.8045678416963299, recall 0.8163151140215209, F1 0.8029384222047992, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7625406215324322, recall 0.7699091746742135, F1 0.6982268978800537, support None
Test score: precision 0.7263253356092481, recall 0.758629767350028, F1 0.6847887168399717, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7470536559173719, recall 0.7739897327892589, F1 0.731222578497255, support None
Test score: precision 0.7408891549109808, recall 0.7692586133140281, F1 0.7246012294380897, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7303744388557554, recall 0.7646439383967355, F1 0.7221640138097073, support None
Test score: precision 0.7069823003826086, recall 0.7501398532363684, F1 0.7049701104576007, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7595223221508675, recall 0.7767613281121458, F1 0.7265284258530329, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Mean results : 0.7202437605212287
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.5 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: scale
Epoch 0, Loss: 96.4940
Epoch 1, Loss: 100.1078
Epoch 2, Loss: 100.1078
Epoch 3, Loss: 100.1078
Epoch 4, Loss: 100.1078
Epoch 5, Loss: 100.1078
Epoch 6, Loss: 100.1078
Epoch 7, Loss: 100.1078
Epoch 8, Loss: 100.1078
Epoch 9, Loss: 100.1078
Epoch 10, Loss: 100.1078
Epoch 11, Loss: 100.1078
Epoch 12, Loss: 100.1078
Epoch 13, Loss: 100.1078
Epoch 14, Loss: 100.1078
Epoch 15, Loss: 100.1078
Epoch 16, Loss: 100.1078
Epoch 17, Loss: 100.1078
Epoch 18, Loss: 100.1078
Epoch 19, Loss: 100.1078
Epoch 20, Loss: 100.1078
Epoch 21, Loss: 100.1078
Epoch 22, Loss: 100.1078
Epoch 23, Loss: 100.1078
Epoch 24, Loss: 100.1078
Epoch 25, Loss: 100.1078
Epoch 26, Loss: 100.1078
Epoch 27, Loss: 100.1078
Epoch 28, Loss: 100.1078
Epoch 29, Loss: 100.1078
Epoch 30, Loss: 100.1078
Epoch 31, Loss: 100.1078
Epoch 32, Loss: 100.1078
Epoch 33, Loss: 100.1078
Epoch 34, Loss: 100.1078
Epoch 35, Loss: 100.1078
Epoch 36, Loss: 100.1078
Epoch 37, Loss: 100.1078
Epoch 38, Loss: 100.1078
Epoch 39, Loss: 100.1078
Epoch 40, Loss: 100.1078
Epoch 41, Loss: 100.1078
Epoch 42, Loss: 100.1078
Epoch 43, Loss: 100.1078
Epoch 44, Loss: 100.1078
Epoch 45, Loss: 100.1078
Epoch 46, Loss: 100.1078
Epoch 47, Loss: 100.1078
Epoch 48, Loss: 100.1078
Epoch 49, Loss: 100.1078
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-scale_at-1.0rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.5 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: model_replacement
Epoch 0, Loss: 20.6188
Epoch 1, Loss: 15.5862
Epoch 2, Loss: 14.7341
Epoch 3, Loss: 14.2666
Epoch 4, Loss: 14.7248
Epoch 5, Loss: 13.9848
Epoch 6, Loss: 13.9072
Epoch 7, Loss: 13.8302
Epoch 8, Loss: 13.8564
Epoch 9, Loss: 14.2936
Epoch 10, Loss: 13.7317
Epoch 11, Loss: 13.6823
Epoch 12, Loss: 13.5737
Epoch 13, Loss: 13.6060
Epoch 14, Loss: 13.5991
Epoch 15, Loss: 13.5049
Epoch 16, Loss: 13.4744
Epoch 17, Loss: 16.5504
Epoch 18, Loss: 14.5918
Epoch 19, Loss: 13.9492
Epoch 20, Loss: 13.6994
Epoch 21, Loss: 13.6371
Epoch 22, Loss: 13.5997
Epoch 23, Loss: 13.5730
Epoch 24, Loss: 13.4992
Epoch 25, Loss: 13.5103
Epoch 26, Loss: 13.4717
Epoch 27, Loss: 13.4201
Epoch 28, Loss: 13.4560
Epoch 29, Loss: 16.9804
Epoch 30, Loss: 14.6414
Epoch 31, Loss: 13.9289
Epoch 32, Loss: 13.7325
Epoch 33, Loss: 13.6456
Epoch 34, Loss: 13.5345
Epoch 35, Loss: 13.5106
Epoch 36, Loss: 13.4667
Epoch 37, Loss: 13.4590
Epoch 38, Loss: 13.4409
Epoch 39, Loss: 14.0533
Epoch 40, Loss: 13.6477
Epoch 41, Loss: 13.4955
Epoch 42, Loss: 13.4957
Epoch 43, Loss: 13.4752
Epoch 44, Loss: 13.4493
Epoch 45, Loss: 13.4498
Epoch 46, Loss: 15.2847
Epoch 47, Loss: 13.9806
Epoch 48, Loss: 13.5794
Epoch 49, Loss: 13.4640
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7235559379385614, recall 0.7568857152259041, F1 0.6776356583338788, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142615593426574, recall 0.8247992628669212, F1 0.8123165500837949, support None
Test score: precision 0.8045678416963299, recall 0.8163151140215209, F1 0.8029384222047992, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7625406215324322, recall 0.7699091746742135, F1 0.6982268978800537, support None
Test score: precision 0.7263253356092481, recall 0.758629767350028, F1 0.6847887168399717, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7470536559173719, recall 0.7739897327892589, F1 0.731222578497255, support None
Test score: precision 0.7408891549109808, recall 0.7692586133140281, F1 0.7246012294380897, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7303744388557554, recall 0.7646439383967355, F1 0.7221640138097073, support None
Test score: precision 0.7069823003826086, recall 0.7501398532363684, F1 0.7049701104576007, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7595223221508675, recall 0.7767613281121458, F1 0.7265284258530329, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Mean results : 0.7202437605212287
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.5 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.5 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: gradient_ascent
Epoch 0, Loss: 35522910662085959139459072.0000
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.5 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: targeted
Epoch 0, Loss: 20.6188
Epoch 1, Loss: 15.5862
Epoch 2, Loss: 14.7341
Epoch 3, Loss: 14.2666
Epoch 4, Loss: 14.7248
Epoch 5, Loss: 13.9848
Epoch 6, Loss: 13.9072
Epoch 7, Loss: 13.8302
Epoch 8, Loss: 13.8564
Epoch 9, Loss: 14.2936
Epoch 10, Loss: 13.7317
Epoch 11, Loss: 13.6823
Epoch 12, Loss: 13.5737
Epoch 13, Loss: 13.6060
Epoch 14, Loss: 13.5991
Epoch 15, Loss: 13.5049
Epoch 16, Loss: 13.4744
Epoch 17, Loss: 16.5504
Epoch 18, Loss: 14.5918
Epoch 19, Loss: 13.9492
Epoch 20, Loss: 13.6994
Epoch 21, Loss: 13.6371
Epoch 22, Loss: 13.5997
Epoch 23, Loss: 13.5730
Epoch 24, Loss: 13.4992
Epoch 25, Loss: 13.5103
Epoch 26, Loss: 13.4717
Epoch 27, Loss: 13.4201
Epoch 28, Loss: 13.4560
Epoch 29, Loss: 16.9804
Epoch 30, Loss: 14.6414
Epoch 31, Loss: 13.9289
Epoch 32, Loss: 13.7325
Epoch 33, Loss: 13.6456
Epoch 34, Loss: 13.5345
Epoch 35, Loss: 13.5106
Epoch 36, Loss: 13.4667
Epoch 37, Loss: 13.4590
Epoch 38, Loss: 13.4409
Epoch 39, Loss: 14.0533
Epoch 40, Loss: 13.6477
Epoch 41, Loss: 13.4955
Epoch 42, Loss: 13.4957
Epoch 43, Loss: 13.4752
Epoch 44, Loss: 13.4493
Epoch 45, Loss: 13.4498
Epoch 46, Loss: 15.2847
Epoch 47, Loss: 13.9806
Epoch 48, Loss: 13.5794
Epoch 49, Loss: 13.4640
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7235559379385614, recall 0.7568857152259041, F1 0.6776356583338788, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142615593426574, recall 0.8247992628669212, F1 0.8123165500837949, support None
Test score: precision 0.8045678416963299, recall 0.8163151140215209, F1 0.8029384222047992, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7625406215324322, recall 0.7699091746742135, F1 0.6982268978800537, support None
Test score: precision 0.7263253356092481, recall 0.758629767350028, F1 0.6847887168399717, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7470536559173719, recall 0.7739897327892589, F1 0.731222578497255, support None
Test score: precision 0.7408891549109808, recall 0.7692586133140281, F1 0.7246012294380897, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7303744388557554, recall 0.7646439383967355, F1 0.7221640138097073, support None
Test score: precision 0.7069823003826086, recall 0.7501398532363684, F1 0.7049701104576007, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7595223221508675, recall 0.7767613281121458, F1 0.7265284258530329, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Mean results : 0.7202437605212287
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.75 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: scale
Epoch 0, Loss: 99.9084
Epoch 1, Loss: 100.1078
Epoch 2, Loss: 100.1078
Epoch 3, Loss: 100.1078
Epoch 4, Loss: 100.1078
Epoch 5, Loss: 100.1078
Epoch 6, Loss: 100.1078
Epoch 7, Loss: 100.1078
Epoch 8, Loss: 100.1078
Epoch 9, Loss: 100.1078
Epoch 10, Loss: 100.1078
Epoch 11, Loss: 100.1078
Epoch 12, Loss: 100.1078
Epoch 13, Loss: 100.1078
Epoch 14, Loss: 100.1078
Epoch 15, Loss: 100.1078
Epoch 16, Loss: 100.1078
Epoch 17, Loss: 100.1078
Epoch 18, Loss: 100.1078
Epoch 19, Loss: 100.1078
Epoch 20, Loss: 100.1078
Epoch 21, Loss: 100.1078
Epoch 22, Loss: 100.1078
Epoch 23, Loss: 100.1078
Epoch 24, Loss: 100.1078
Epoch 25, Loss: 100.1078
Epoch 26, Loss: 100.1078
Epoch 27, Loss: 100.1078
Epoch 28, Loss: 100.1078
Epoch 29, Loss: 100.1078
Epoch 30, Loss: 100.1078
Epoch 31, Loss: 100.1078
Epoch 32, Loss: 100.1078
Epoch 33, Loss: 100.1078
Epoch 34, Loss: 100.1078
Epoch 35, Loss: 100.1078
Epoch 36, Loss: 100.1078
Epoch 37, Loss: 100.1078
Epoch 38, Loss: 100.1078
Epoch 39, Loss: 100.1078
Epoch 40, Loss: 100.1078
Epoch 41, Loss: 100.1078
Epoch 42, Loss: 100.1078
Epoch 43, Loss: 100.1078
Epoch 44, Loss: 100.1078
Epoch 45, Loss: 100.1078
Epoch 46, Loss: 100.1078
Epoch 47, Loss: 100.1078
Epoch 48, Loss: 100.1078
Epoch 49, Loss: 100.1078
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-scale_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-scale_at-1.0rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.75 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: model_replacement
Epoch 0, Loss: 20.6188
Epoch 1, Loss: 15.5862
Epoch 2, Loss: 14.7341
Epoch 3, Loss: 14.2666
Epoch 4, Loss: 14.7248
Epoch 5, Loss: 13.9848
Epoch 6, Loss: 13.9072
Epoch 7, Loss: 13.8302
Epoch 8, Loss: 13.8564
Epoch 9, Loss: 14.2936
Epoch 10, Loss: 13.7317
Epoch 11, Loss: 13.6823
Epoch 12, Loss: 13.5737
Epoch 13, Loss: 13.6060
Epoch 14, Loss: 13.5991
Epoch 15, Loss: 13.5049
Epoch 16, Loss: 13.4744
Epoch 17, Loss: 16.5504
Epoch 18, Loss: 14.5918
Epoch 19, Loss: 13.9492
Epoch 20, Loss: 13.6994
Epoch 21, Loss: 13.6371
Epoch 22, Loss: 13.5997
Epoch 23, Loss: 13.5730
Epoch 24, Loss: 13.4992
Epoch 25, Loss: 13.5103
Epoch 26, Loss: 13.4717
Epoch 27, Loss: 13.4201
Epoch 28, Loss: 13.4560
Epoch 29, Loss: 16.9804
Epoch 30, Loss: 14.6414
Epoch 31, Loss: 13.9289
Epoch 32, Loss: 13.7325
Epoch 33, Loss: 13.6456
Epoch 34, Loss: 13.5345
Epoch 35, Loss: 13.5106
Epoch 36, Loss: 13.4667
Epoch 37, Loss: 13.4590
Epoch 38, Loss: 13.4409
Epoch 39, Loss: 14.0533
Epoch 40, Loss: 13.6477
Epoch 41, Loss: 13.4955
Epoch 42, Loss: 13.4957
Epoch 43, Loss: 13.4752
Epoch 44, Loss: 13.4493
Epoch 45, Loss: 13.4498
Epoch 46, Loss: 15.2847
Epoch 47, Loss: 13.9806
Epoch 48, Loss: 13.5794
Epoch 49, Loss: 13.4640
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7235559379385614, recall 0.7568857152259041, F1 0.6776356583338788, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142615593426574, recall 0.8247992628669212, F1 0.8123165500837949, support None
Test score: precision 0.8045678416963299, recall 0.8163151140215209, F1 0.8029384222047992, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7625406215324322, recall 0.7699091746742135, F1 0.6982268978800537, support None
Test score: precision 0.7263253356092481, recall 0.758629767350028, F1 0.6847887168399717, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7470536559173719, recall 0.7739897327892589, F1 0.731222578497255, support None
Test score: precision 0.7408891549109808, recall 0.7692586133140281, F1 0.7246012294380897, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7303744388557554, recall 0.7646439383967355, F1 0.7221640138097073, support None
Test score: precision 0.7069823003826086, recall 0.7501398532363684, F1 0.7049701104576007, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7595223221508675, recall 0.7767613281121458, F1 0.7265284258530329, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-model_replacement_at-1.0rl-blog.csv
====================================================================================================

Mean results : 0.7202437605212287
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.75 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.75 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: gradient_ascent
Epoch 0, Loss: inf
python -W ignore adv_train.py -d blog -e 50 -rl 1 -mc 0.75 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: targeted
Epoch 0, Loss: 20.6188
Epoch 1, Loss: 15.5862
Epoch 2, Loss: 14.7341
Epoch 3, Loss: 14.2666
Epoch 4, Loss: 14.7248
Epoch 5, Loss: 13.9848
Epoch 6, Loss: 13.9072
Epoch 7, Loss: 13.8302
Epoch 8, Loss: 13.8564
Epoch 9, Loss: 14.2936
Epoch 10, Loss: 13.7317
Epoch 11, Loss: 13.6823
Epoch 12, Loss: 13.5737
Epoch 13, Loss: 13.6060
Epoch 14, Loss: 13.5991
Epoch 15, Loss: 13.5049
Epoch 16, Loss: 13.4744
Epoch 17, Loss: 16.5504
Epoch 18, Loss: 14.5918
Epoch 19, Loss: 13.9492
Epoch 20, Loss: 13.6994
Epoch 21, Loss: 13.6371
Epoch 22, Loss: 13.5997
Epoch 23, Loss: 13.5730
Epoch 24, Loss: 13.4992
Epoch 25, Loss: 13.5103
Epoch 26, Loss: 13.4717
Epoch 27, Loss: 13.4201
Epoch 28, Loss: 13.4560
Epoch 29, Loss: 16.9804
Epoch 30, Loss: 14.6414
Epoch 31, Loss: 13.9289
Epoch 32, Loss: 13.7325
Epoch 33, Loss: 13.6456
Epoch 34, Loss: 13.5345
Epoch 35, Loss: 13.5106
Epoch 36, Loss: 13.4667
Epoch 37, Loss: 13.4590
Epoch 38, Loss: 13.4409
Epoch 39, Loss: 14.0533
Epoch 40, Loss: 13.6477
Epoch 41, Loss: 13.4955
Epoch 42, Loss: 13.4957
Epoch 43, Loss: 13.4752
Epoch 44, Loss: 13.4493
Epoch 45, Loss: 13.4498
Epoch 46, Loss: 15.2847
Epoch 47, Loss: 13.9806
Epoch 48, Loss: 13.5794
Epoch 49, Loss: 13.4640
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7235559379385614, recall 0.7568857152259041, F1 0.6776356583338788, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142615593426574, recall 0.8247992628669212, F1 0.8123165500837949, support None
Test score: precision 0.8045678416963299, recall 0.8163151140215209, F1 0.8029384222047992, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7625406215324322, recall 0.7699091746742135, F1 0.6982268978800537, support None
Test score: precision 0.7263253356092481, recall 0.758629767350028, F1 0.6847887168399717, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7470536559173719, recall 0.7739897327892589, F1 0.731222578497255, support None
Test score: precision 0.7408891549109808, recall 0.7692586133140281, F1 0.7246012294380897, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7303744388557554, recall 0.7646439383967355, F1 0.7221640138097073, support None
Test score: precision 0.7069823003826086, recall 0.7501398532363684, F1 0.7049701104576007, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7595223221508675, recall 0.7767613281121458, F1 0.7265284258530329, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-targeted_at-1.0rl-blog.csv
====================================================================================================

Mean results : 0.7202437605212287
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.25 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: scale
Epoch 0, Loss: 95.0703
Epoch 1, Loss: 100.1074
Epoch 2, Loss: 100.1071
Epoch 3, Loss: 100.1074
Epoch 4, Loss: 100.1075
Epoch 5, Loss: 100.1075
Epoch 6, Loss: 100.1073
Epoch 7, Loss: 100.1075
Epoch 8, Loss: 100.1072
Epoch 9, Loss: 100.1074
Epoch 10, Loss: 100.1074
Warning: Model parameters were not updated for client 1
Epoch 11, Loss: 100.1074
Epoch 12, Loss: 100.1074
Epoch 13, Loss: 100.1075
Epoch 14, Loss: 100.1074
Epoch 15, Loss: 100.1073
Epoch 16, Loss: 100.1072
Warning: Model parameters were not updated for client 4
Epoch 17, Loss: 100.1074
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Epoch 18, Loss: 100.1073
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Epoch 19, Loss: 100.1074
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Epoch 20, Loss: 100.1074
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Epoch 21, Loss: 100.1074
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Epoch 22, Loss: 100.1073
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Epoch 23, Loss: 100.1075
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Epoch 24, Loss: 100.1074
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Epoch 25, Loss: 100.1075
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Epoch 26, Loss: 100.1074
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Epoch 27, Loss: 100.1073
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Epoch 28, Loss: 100.1072
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Epoch 29, Loss: 100.1073
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Epoch 30, Loss: 100.1074
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Epoch 31, Loss: 100.1074
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Epoch 32, Loss: 100.1074
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Epoch 33, Loss: 100.1075
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Epoch 34, Loss: 100.1072
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Epoch 35, Loss: 100.1074
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Epoch 36, Loss: 100.1075
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Epoch 37, Loss: 100.1074
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Epoch 38, Loss: 100.1074
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Epoch 39, Loss: 100.1076
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Epoch 40, Loss: 100.1072
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Epoch 41, Loss: 100.1073
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Epoch 42, Loss: 100.1072
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Epoch 43, Loss: 100.1074
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Epoch 44, Loss: 100.1074
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Epoch 45, Loss: 100.1074
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Epoch 46, Loss: 100.1070
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Epoch 47, Loss: 100.1074
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Epoch 48, Loss: 100.1075
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 3
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 5
Epoch 49, Loss: 100.1074
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-scale_at-0.25rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.25 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: model_replacement
Epoch 0, Loss: 23.2228
Epoch 1, Loss: 17.4566
Epoch 2, Loss: 16.2511
Epoch 3, Loss: 15.7374
Epoch 4, Loss: 15.4740
Epoch 5, Loss: 15.2227
Epoch 6, Loss: 15.2708
Epoch 7, Loss: 15.0511
Epoch 8, Loss: 14.9503
Epoch 9, Loss: 14.9004
Epoch 10, Loss: 14.9215
Epoch 11, Loss: 14.6183
Epoch 12, Loss: 14.7970
Epoch 13, Loss: 14.5131
Epoch 14, Loss: 14.4279
Epoch 15, Loss: 14.7012
Epoch 16, Loss: 14.2414
Epoch 17, Loss: 14.3503
Epoch 18, Loss: 14.1748
Epoch 19, Loss: 14.2078
Epoch 20, Loss: 14.0550
Epoch 21, Loss: 14.3179
Epoch 22, Loss: 14.5369
Epoch 23, Loss: 14.0114
Epoch 24, Loss: 13.9138
Epoch 25, Loss: 13.9844
Epoch 26, Loss: 13.9959
Epoch 27, Loss: 14.1331
Epoch 28, Loss: 13.8847
Epoch 29, Loss: 14.5288
Epoch 30, Loss: 13.8590
Epoch 31, Loss: 13.8664
Epoch 32, Loss: 13.8035
Epoch 33, Loss: 14.1220
Epoch 34, Loss: 13.8309
Epoch 35, Loss: 13.7502
Epoch 36, Loss: 14.1930
Epoch 37, Loss: 13.8748
Epoch 38, Loss: 13.6898
Epoch 39, Loss: 13.7763
Epoch 40, Loss: 13.6794
Epoch 41, Loss: 14.0581
Epoch 42, Loss: 13.7165
Epoch 43, Loss: 13.7033
Epoch 44, Loss: 13.9350
Epoch 45, Loss: 13.6346
Epoch 46, Loss: 14.1060
Epoch 47, Loss: 13.8244
Epoch 48, Loss: 13.6023
Epoch 49, Loss: 13.6308
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7386147900529559, recall 0.7629327366065553, F1 0.6868410050512117, support None
Test score: precision 0.7245684580096531, recall 0.7570831550890125, F1 0.6777576199297272, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142606295196833, recall 0.8247992628669212, F1 0.8123691057735665, support None
Test score: precision 0.8041810534286152, recall 0.815986047583007, F1 0.8026952565055102, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7626571955366969, recall 0.7696459128603396, F1 0.6973652705314726, support None
Test score: precision 0.7292170750128522, recall 0.7592879002270558, F1 0.6851223607126544, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7477302023709217, recall 0.7743846255100698, F1 0.7318635916711562, support None
Test score: precision 0.7400155193121783, recall 0.76883082694396, F1 0.7245747679499092, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7295437645189814, recall 0.7643806765828617, F1 0.719013855739931, support None
Test score: precision 0.7038909080658852, recall 0.7490539339892724, F1 0.7013756477227526, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.760091834364936, recall 0.7769587679752542, F1 0.7266117560957779, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Mean results : 0.719689568152722
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.25 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.25 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: gradient_ascent
Epoch 0, Loss: 2844.9518
Epoch 1, Loss: 2570650509269078.0000
Epoch 2, Loss: 49765707091134860509157785600.0000
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 5
Warning: Model parameters were not updated for client 2
Epoch 3, Loss: inf
Warning: Model parameters were not updated for client 2
Warning: Model parameters were not updated for client 4
Warning: Model parameters were not updated for client 1
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.25 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: targeted
Epoch 0, Loss: 23.2228
Epoch 1, Loss: 17.4566
Epoch 2, Loss: 16.2511
Epoch 3, Loss: 15.7374
Epoch 4, Loss: 15.4740
Epoch 5, Loss: 15.2227
Epoch 6, Loss: 15.2708
Epoch 7, Loss: 15.0511
Epoch 8, Loss: 14.9503
Epoch 9, Loss: 14.9004
Epoch 10, Loss: 14.9215
Epoch 11, Loss: 14.6183
Epoch 12, Loss: 14.7970
Epoch 13, Loss: 14.5131
Epoch 14, Loss: 14.4279
Epoch 15, Loss: 14.7012
Epoch 16, Loss: 14.2414
Epoch 17, Loss: 14.3503
Epoch 18, Loss: 14.1748
Epoch 19, Loss: 14.2078
Epoch 20, Loss: 14.0550
Epoch 21, Loss: 14.3179
Epoch 22, Loss: 14.5369
Epoch 23, Loss: 14.0114
Epoch 24, Loss: 13.9138
Epoch 25, Loss: 13.9844
Epoch 26, Loss: 13.9959
Epoch 27, Loss: 14.1331
Epoch 28, Loss: 13.8847
Epoch 29, Loss: 14.5288
Epoch 30, Loss: 13.8590
Epoch 31, Loss: 13.8664
Epoch 32, Loss: 13.8035
Epoch 33, Loss: 14.1220
Epoch 34, Loss: 13.8309
Epoch 35, Loss: 13.7502
Epoch 36, Loss: 14.1930
Epoch 37, Loss: 13.8748
Epoch 38, Loss: 13.6898
Epoch 39, Loss: 13.7763
Epoch 40, Loss: 13.6794
Epoch 41, Loss: 14.0581
Epoch 42, Loss: 13.7165
Epoch 43, Loss: 13.7033
Epoch 44, Loss: 13.9350
Epoch 45, Loss: 13.6346
Epoch 46, Loss: 14.1060
Epoch 47, Loss: 13.8244
Epoch 48, Loss: 13.6023
Epoch 49, Loss: 13.6308
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7386147900529559, recall 0.7629327366065553, F1 0.6868410050512117, support None
Test score: precision 0.7245684580096531, recall 0.7570831550890125, F1 0.6777576199297272, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142606295196833, recall 0.8247992628669212, F1 0.8123691057735665, support None
Test score: precision 0.8041810534286152, recall 0.815986047583007, F1 0.8026952565055102, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7626571955366969, recall 0.7696459128603396, F1 0.6973652705314726, support None
Test score: precision 0.7292170750128522, recall 0.7592879002270558, F1 0.6851223607126544, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7477302023709217, recall 0.7743846255100698, F1 0.7318635916711562, support None
Test score: precision 0.7400155193121783, recall 0.76883082694396, F1 0.7245747679499092, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7295437645189814, recall 0.7643806765828617, F1 0.719013855739931, support None
Test score: precision 0.7038909080658852, recall 0.7490539339892724, F1 0.7013756477227526, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.760091834364936, recall 0.7769587679752542, F1 0.7266117560957779, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Mean results : 0.719689568152722
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.5 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: scale
Epoch 0, Loss: 99.6817
Epoch 1, Loss: 100.1078
Epoch 2, Loss: 100.1078
Epoch 3, Loss: 100.1078
Epoch 4, Loss: 100.1078
Epoch 5, Loss: 100.1078
Epoch 6, Loss: 100.1077
Epoch 7, Loss: 100.1078
Epoch 8, Loss: 100.1078
Warning: Model parameters were not updated for client 3
Epoch 9, Loss: 100.1078
Epoch 10, Loss: 100.1078
Epoch 11, Loss: 100.1078
Epoch 12, Loss: 100.1078
Epoch 13, Loss: 100.1078
Epoch 14, Loss: 100.1077
Epoch 15, Loss: 100.1078
Epoch 16, Loss: 100.1078
Epoch 17, Loss: 100.1078
Epoch 18, Loss: 100.1078
Epoch 19, Loss: 100.1078
Epoch 20, Loss: 100.1078
Epoch 21, Loss: 100.1078
Epoch 22, Loss: 100.1077
Epoch 23, Loss: 100.1078
Epoch 24, Loss: 100.1078
Epoch 25, Loss: 100.1077
Epoch 26, Loss: 100.1078
Epoch 27, Loss: 100.1078
Epoch 28, Loss: 100.1078
Epoch 29, Loss: 100.1078
Epoch 30, Loss: 100.1078
Epoch 31, Loss: 100.1078
Epoch 32, Loss: 100.1078
Epoch 33, Loss: 100.1078
Epoch 34, Loss: 100.1078
Epoch 35, Loss: 100.1078
Epoch 36, Loss: 100.1078
Epoch 37, Loss: 100.1078
Epoch 38, Loss: 100.1078
Warning: Model parameters were not updated for client 4
Epoch 39, Loss: 100.1078
Epoch 40, Loss: 100.1078
Epoch 41, Loss: 100.1078
Epoch 42, Loss: 100.1078
Epoch 43, Loss: 100.1078
Warning: Model parameters were not updated for client 1
Epoch 44, Loss: 100.1078
Epoch 45, Loss: 100.1078
Epoch 46, Loss: 100.1077
Epoch 47, Loss: 100.1078
Epoch 48, Loss: 100.1078
Epoch 49, Loss: 100.1077
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-scale_at-0.25rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.5 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: model_replacement
Epoch 0, Loss: 23.9416
Epoch 1, Loss: 17.8869
Epoch 2, Loss: 16.4623
Epoch 3, Loss: 15.9111
Epoch 4, Loss: 15.5447
Epoch 5, Loss: 15.1930
Epoch 6, Loss: 15.1005
Epoch 7, Loss: 15.2013
Epoch 8, Loss: 14.8655
Epoch 9, Loss: 15.0559
Epoch 10, Loss: 14.6383
Epoch 11, Loss: 14.7368
Epoch 12, Loss: 14.5628
Epoch 13, Loss: 14.4654
Epoch 14, Loss: 15.2096
Epoch 15, Loss: 14.3552
Epoch 16, Loss: 14.2858
Epoch 17, Loss: 14.3994
Epoch 18, Loss: 14.6105
Epoch 19, Loss: 14.6231
Epoch 20, Loss: 14.1641
Epoch 21, Loss: 14.1440
Epoch 22, Loss: 14.1441
Epoch 23, Loss: 14.6598
Epoch 24, Loss: 14.0444
Epoch 25, Loss: 14.0416
Epoch 26, Loss: 14.0893
Epoch 27, Loss: 13.9220
Epoch 28, Loss: 13.9760
Epoch 29, Loss: 13.9224
Epoch 30, Loss: 14.3445
Epoch 31, Loss: 13.8464
Epoch 32, Loss: 13.7780
Epoch 33, Loss: 13.9896
Epoch 34, Loss: 13.8271
Epoch 35, Loss: 13.7551
Epoch 36, Loss: 14.1500
Epoch 37, Loss: 13.8268
Epoch 38, Loss: 13.6857
Epoch 39, Loss: 13.7252
Epoch 40, Loss: 13.7898
Epoch 41, Loss: 14.7140
Epoch 42, Loss: 13.7820
Epoch 43, Loss: 13.7567
Epoch 44, Loss: 13.6893
Epoch 45, Loss: 13.6641
Epoch 46, Loss: 13.7198
Epoch 47, Loss: 13.6264
Epoch 48, Loss: 13.7418
Epoch 49, Loss: 13.5960
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.722019234323026, recall 0.7565895554312416, F1 0.6774992873132383, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.813983122707273, recall 0.8245360010530473, F1 0.812968470520652, support None
Test score: precision 0.8055604909317984, recall 0.817071966830103, F1 0.8047268768762899, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7625967065466549, recall 0.7697775437672766, F1 0.6977966300403818, support None
Test score: precision 0.7295449467487283, recall 0.7594195268024614, F1 0.6854700782735966, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7479289724978964, recall 0.7745162564170067, F1 0.7321908559693319, support None
Test score: precision 0.7383117181225533, recall 0.7679423475599724, F1 0.7241439764138848, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7298977276721965, recall 0.7646439383967355, F1 0.7171169066581594, support None
Test score: precision 0.7053700568533189, recall 0.7500082266609629, F1 0.7019587641836472, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7631102076143987, recall 0.7791233381598, F1 0.72746948288809, support None
Test score: precision 0.7597497017780522, recall 0.7767942347559972, F1 0.7263941968987696, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Mean results : 0.7200321966599043
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.5 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.5 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: gradient_ascent
Epoch 0, Loss: 63584416752466542876164096.0000
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.5 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: targeted
Epoch 0, Loss: 23.9416
Epoch 1, Loss: 17.8869
Epoch 2, Loss: 16.4623
Epoch 3, Loss: 15.9111
Epoch 4, Loss: 15.5447
Epoch 5, Loss: 15.1930
Epoch 6, Loss: 15.1005
Epoch 7, Loss: 15.2013
Epoch 8, Loss: 14.8655
Epoch 9, Loss: 15.0559
Epoch 10, Loss: 14.6383
Epoch 11, Loss: 14.7368
Epoch 12, Loss: 14.5628
Epoch 13, Loss: 14.4654
Epoch 14, Loss: 15.2096
Epoch 15, Loss: 14.3552
Epoch 16, Loss: 14.2858
Epoch 17, Loss: 14.3994
Epoch 18, Loss: 14.6105
Epoch 19, Loss: 14.6231
Epoch 20, Loss: 14.1641
Epoch 21, Loss: 14.1440
Epoch 22, Loss: 14.1441
Epoch 23, Loss: 14.6598
Epoch 24, Loss: 14.0444
Epoch 25, Loss: 14.0416
Epoch 26, Loss: 14.0893
Epoch 27, Loss: 13.9220
Epoch 28, Loss: 13.9760
Epoch 29, Loss: 13.9224
Epoch 30, Loss: 14.3445
Epoch 31, Loss: 13.8464
Epoch 32, Loss: 13.7780
Epoch 33, Loss: 13.9896
Epoch 34, Loss: 13.8271
Epoch 35, Loss: 13.7551
Epoch 36, Loss: 14.1500
Epoch 37, Loss: 13.8268
Epoch 38, Loss: 13.6857
Epoch 39, Loss: 13.7252
Epoch 40, Loss: 13.7898
Epoch 41, Loss: 14.7140
Epoch 42, Loss: 13.7820
Epoch 43, Loss: 13.7567
Epoch 44, Loss: 13.6893
Epoch 45, Loss: 13.6641
Epoch 46, Loss: 13.7198
Epoch 47, Loss: 13.6264
Epoch 48, Loss: 13.7418
Epoch 49, Loss: 13.5960
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.722019234323026, recall 0.7565895554312416, F1 0.6774992873132383, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.813983122707273, recall 0.8245360010530473, F1 0.812968470520652, support None
Test score: precision 0.8055604909317984, recall 0.817071966830103, F1 0.8047268768762899, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7625967065466549, recall 0.7697775437672766, F1 0.6977966300403818, support None
Test score: precision 0.7295449467487283, recall 0.7594195268024614, F1 0.6854700782735966, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7479289724978964, recall 0.7745162564170067, F1 0.7321908559693319, support None
Test score: precision 0.7383117181225533, recall 0.7679423475599724, F1 0.7241439764138848, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7298977276721965, recall 0.7646439383967355, F1 0.7171169066581594, support None
Test score: precision 0.7053700568533189, recall 0.7500082266609629, F1 0.7019587641836472, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7631102076143987, recall 0.7791233381598, F1 0.72746948288809, support None
Test score: precision 0.7597497017780522, recall 0.7767942347559972, F1 0.7263941968987696, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Mean results : 0.7200321966599043
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.75 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: scale
Epoch 0, Loss: 99.9363
Epoch 1, Loss: 100.1079
Epoch 2, Loss: 100.1078
Epoch 3, Loss: 100.1078
Epoch 4, Loss: 100.1078
Epoch 5, Loss: 100.1079
Warning: Model parameters were not updated for client 4
Epoch 6, Loss: 100.1079
Epoch 7, Loss: 100.1078
Epoch 8, Loss: 100.1079
Epoch 9, Loss: 100.1078
Epoch 10, Loss: 100.1078
Epoch 11, Loss: 100.1079
Epoch 12, Loss: 100.1078
Epoch 13, Loss: 100.1079
Epoch 14, Loss: 100.1078
Epoch 15, Loss: 100.1078
Warning: Model parameters were not updated for client 4
Epoch 16, Loss: 100.1078
Epoch 17, Loss: 100.1078
Epoch 18, Loss: 100.1078
Epoch 19, Loss: 100.1078
Epoch 20, Loss: 100.1078
Epoch 21, Loss: 100.1078
Epoch 22, Loss: 100.1078
Epoch 23, Loss: 100.1078
Epoch 24, Loss: 100.1078
Epoch 25, Loss: 100.1079
Epoch 26, Loss: 100.1078
Epoch 27, Loss: 100.1078
Epoch 28, Loss: 100.1078
Epoch 29, Loss: 100.1078
Epoch 30, Loss: 100.1078
Epoch 31, Loss: 100.1078
Epoch 32, Loss: 100.1078
Epoch 33, Loss: 100.1078
Epoch 34, Loss: 100.1078
Epoch 35, Loss: 100.1078
Epoch 36, Loss: 100.1078
Epoch 37, Loss: 100.1078
Epoch 38, Loss: 100.1078
Epoch 39, Loss: 100.1078
Epoch 40, Loss: 100.1078
Epoch 41, Loss: 100.1078
Epoch 42, Loss: 100.1078
Epoch 43, Loss: 100.1078
Epoch 44, Loss: 100.1078
Epoch 45, Loss: 100.1078
Epoch 46, Loss: 100.1078
Epoch 47, Loss: 100.1078
Epoch 48, Loss: 100.1078
Epoch 49, Loss: 100.1078
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-scale_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-scale_at-0.25rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.75 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: model_replacement
Epoch 0, Loss: 23.1387
Epoch 1, Loss: 17.4826
Epoch 2, Loss: 16.1578
Epoch 3, Loss: 15.5148
Epoch 4, Loss: 15.2832
Epoch 5, Loss: 14.8815
Epoch 6, Loss: 14.7903
Epoch 7, Loss: 14.7387
Epoch 8, Loss: 14.7143
Epoch 9, Loss: 14.6538
Epoch 10, Loss: 14.4800
Epoch 11, Loss: 14.4066
Epoch 12, Loss: 14.3957
Epoch 13, Loss: 14.5082
Epoch 14, Loss: 14.3135
Epoch 15, Loss: 14.2123
Epoch 16, Loss: 14.2492
Epoch 17, Loss: 14.3632
Epoch 18, Loss: 14.5587
Epoch 19, Loss: 14.0656
Epoch 20, Loss: 14.0041
Epoch 21, Loss: 14.0159
Epoch 22, Loss: 14.1177
Epoch 23, Loss: 14.7552
Epoch 24, Loss: 14.2541
Epoch 25, Loss: 13.9695
Epoch 26, Loss: 13.9097
Epoch 27, Loss: 13.8388
Epoch 28, Loss: 14.5247
Epoch 29, Loss: 13.9356
Epoch 30, Loss: 13.7718
Epoch 31, Loss: 13.9415
Epoch 32, Loss: 13.7965
Epoch 33, Loss: 13.7398
Epoch 34, Loss: 14.2806
Epoch 35, Loss: 13.7494
Epoch 36, Loss: 13.6532
Epoch 37, Loss: 13.7083
Epoch 38, Loss: 14.2923
Epoch 39, Loss: 13.6898
Epoch 40, Loss: 13.8752
Epoch 41, Loss: 13.7138
Epoch 42, Loss: 13.7329
Epoch 43, Loss: 13.7030
Epoch 44, Loss: 14.0464
Epoch 45, Loss: 13.6465
Epoch 46, Loss: 13.5753
Epoch 47, Loss: 13.7428
Epoch 48, Loss: 13.6410
Epoch 49, Loss: 13.8146
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7398168283709174, recall 0.7630643675134922, F1 0.6865609510316899, support None
Test score: precision 0.7228494809944257, recall 0.7565566487873902, F1 0.6764023022072474, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8141042776276936, recall 0.8246676319599842, F1 0.8124637162764127, support None
Test score: precision 0.8046216345239942, recall 0.8163480206653724, F1 0.8031994720672544, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7622759640671151, recall 0.7696459128603396, F1 0.6975377413463266, support None
Test score: precision 0.728629742020701, recall 0.7591891802955016, F1 0.6852347250444032, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7477302023709217, recall 0.7743846255100698, F1 0.7318635916711562, support None
Test score: precision 0.7389590219355412, recall 0.7682714139984863, F1 0.7241276396706833, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7262736419444545, recall 0.7625378438857444, F1 0.717543445079193, support None
Test score: precision 0.7100208701763574, recall 0.7526736648129257, F1 0.7044589729534353, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7602634411282423, recall 0.777024581262957, F1 0.7266606825320308, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-model_replacement_at-0.25rl-blog.csv
====================================================================================================

Mean results : 0.7200139657458425
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.75 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.75 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: gradient_ascent
Epoch 0, Loss: inf
python -W ignore adv_train.py -d blog -e 50 -rl 0.25 -mc 0.75 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: targeted
Epoch 0, Loss: 23.1387
Epoch 1, Loss: 17.4826
Epoch 2, Loss: 16.1578
Epoch 3, Loss: 15.5148
Epoch 4, Loss: 15.2832
Epoch 5, Loss: 14.8815
Epoch 6, Loss: 14.7903
Epoch 7, Loss: 14.7387
Epoch 8, Loss: 14.7143
Epoch 9, Loss: 14.6538
Epoch 10, Loss: 14.4800
Epoch 11, Loss: 14.4066
Epoch 12, Loss: 14.3957
Epoch 13, Loss: 14.5082
Epoch 14, Loss: 14.3135
Epoch 15, Loss: 14.2123
Epoch 16, Loss: 14.2492
Epoch 17, Loss: 14.3632
Epoch 18, Loss: 14.5587
Epoch 19, Loss: 14.0656
Epoch 20, Loss: 14.0041
Epoch 21, Loss: 14.0159
Epoch 22, Loss: 14.1177
Epoch 23, Loss: 14.7552
Epoch 24, Loss: 14.2541
Epoch 25, Loss: 13.9695
Epoch 26, Loss: 13.9097
Epoch 27, Loss: 13.8388
Epoch 28, Loss: 14.5247
Epoch 29, Loss: 13.9356
Epoch 30, Loss: 13.7718
Epoch 31, Loss: 13.9415
Epoch 32, Loss: 13.7965
Epoch 33, Loss: 13.7398
Epoch 34, Loss: 14.2806
Epoch 35, Loss: 13.7494
Epoch 36, Loss: 13.6532
Epoch 37, Loss: 13.7083
Epoch 38, Loss: 14.2923
Epoch 39, Loss: 13.6898
Epoch 40, Loss: 13.8752
Epoch 41, Loss: 13.7138
Epoch 42, Loss: 13.7329
Epoch 43, Loss: 13.7030
Epoch 44, Loss: 14.0464
Epoch 45, Loss: 13.6465
Epoch 46, Loss: 13.5753
Epoch 47, Loss: 13.7428
Epoch 48, Loss: 13.6410
Epoch 49, Loss: 13.8146
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7398168283709174, recall 0.7630643675134922, F1 0.6865609510316899, support None
Test score: precision 0.7228494809944257, recall 0.7565566487873902, F1 0.6764023022072474, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8141042776276936, recall 0.8246676319599842, F1 0.8124637162764127, support None
Test score: precision 0.8046216345239942, recall 0.8163480206653724, F1 0.8031994720672544, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7622759640671151, recall 0.7696459128603396, F1 0.6975377413463266, support None
Test score: precision 0.728629742020701, recall 0.7591891802955016, F1 0.6852347250444032, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7477302023709217, recall 0.7743846255100698, F1 0.7318635916711562, support None
Test score: precision 0.7389590219355412, recall 0.7682714139984863, F1 0.7241276396706833, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7262736419444545, recall 0.7625378438857444, F1 0.717543445079193, support None
Test score: precision 0.7100208701763574, recall 0.7526736648129257, F1 0.7044589729534353, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7602634411282423, recall 0.777024581262957, F1 0.7266606825320308, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-targeted_at-0.25rl-blog.csv
====================================================================================================

Mean results : 0.7200139657458425
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.25 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: scale
Epoch 0, Loss: 67.5708
Epoch 1, Loss: 64.8926
Epoch 2, Loss: 61.1152
Epoch 3, Loss: 63.9643
Epoch 4, Loss: 63.4262
Epoch 5, Loss: 64.5158
Epoch 6, Loss: 61.6502
Epoch 7, Loss: 67.0571
Epoch 8, Loss: 62.6173
Epoch 9, Loss: 63.8125
Epoch 10, Loss: 65.1604
Epoch 11, Loss: 77.5668
Epoch 12, Loss: 100.1074
Epoch 13, Loss: 100.1074
Epoch 14, Loss: 100.1074
Epoch 15, Loss: 100.1073
Epoch 16, Loss: 100.1074
Epoch 17, Loss: 100.1074
Epoch 18, Loss: 100.1074
Epoch 19, Loss: 100.1074
Epoch 20, Loss: 100.1073
Epoch 21, Loss: 100.1074
Epoch 22, Loss: 100.1074
Epoch 23, Loss: 100.1074
Epoch 24, Loss: 100.1074
Epoch 25, Loss: 100.1073
Epoch 26, Loss: 100.1073
Epoch 27, Loss: 100.1074
Epoch 28, Loss: 100.1074
Epoch 29, Loss: 100.1074
Epoch 30, Loss: 100.1074
Epoch 31, Loss: 100.1074
Epoch 32, Loss: 100.1074
Epoch 33, Loss: 100.1073
Epoch 34, Loss: 100.1074
Epoch 35, Loss: 100.1074
Epoch 36, Loss: 100.1074
Epoch 37, Loss: 100.1074
Epoch 38, Loss: 100.1074
Epoch 39, Loss: 100.1074
Epoch 40, Loss: 100.1074
Epoch 41, Loss: 100.1073
Epoch 42, Loss: 100.1074
Epoch 43, Loss: 100.1074
Epoch 44, Loss: 100.1074
Epoch 45, Loss: 100.1074
Epoch 46, Loss: 100.1074
Epoch 47, Loss: 100.1074
Epoch 48, Loss: 100.1074
Epoch 49, Loss: 100.1074
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-scale_at-0.5rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.25 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: model_replacement
Epoch 0, Loss: 21.6730
Epoch 1, Loss: 16.4675
Epoch 2, Loss: 15.4235
Epoch 3, Loss: 14.8860
Epoch 4, Loss: 14.5715
Epoch 5, Loss: 14.4489
Epoch 6, Loss: 14.2703
Epoch 7, Loss: 14.1697
Epoch 8, Loss: 14.1156
Epoch 9, Loss: 14.1313
Epoch 10, Loss: 13.9633
Epoch 11, Loss: 13.8914
Epoch 12, Loss: 13.8242
Epoch 13, Loss: 14.2406
Epoch 14, Loss: 13.8149
Epoch 15, Loss: 13.6996
Epoch 16, Loss: 13.6729
Epoch 17, Loss: 13.7416
Epoch 18, Loss: 14.0152
Epoch 19, Loss: 13.6390
Epoch 20, Loss: 13.5688
Epoch 21, Loss: 13.5955
Epoch 22, Loss: 13.7155
Epoch 23, Loss: 13.6395
Epoch 24, Loss: 13.8206
Epoch 25, Loss: 13.7889
Epoch 26, Loss: 13.5669
Epoch 27, Loss: 13.5645
Epoch 28, Loss: 13.5590
Epoch 29, Loss: 13.8009
Epoch 30, Loss: 13.5403
Epoch 31, Loss: 13.4990
Epoch 32, Loss: 13.5156
Epoch 33, Loss: 13.8358
Epoch 34, Loss: 13.4930
Epoch 35, Loss: 13.4566
Epoch 36, Loss: 13.4564
Epoch 37, Loss: 13.5155
Epoch 38, Loss: 14.0760
Epoch 39, Loss: 13.5033
Epoch 40, Loss: 13.4448
Epoch 41, Loss: 14.8465
Epoch 42, Loss: 13.8788
Epoch 43, Loss: 13.6422
Epoch 44, Loss: 13.5526
Epoch 45, Loss: 13.5514
Epoch 46, Loss: 13.4350
Epoch 47, Loss: 13.5489
Epoch 48, Loss: 13.4748
Epoch 49, Loss: 14.2052
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7237238279047666, recall 0.7569186218697556, F1 0.677655984526737, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8140888871934375, recall 0.8245360010530473, F1 0.8105791744353261, support None
Test score: precision 0.8045927047952299, recall 0.8163151140215209, F1 0.8015072998919159, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7622217896481026, recall 0.7697775437672766, F1 0.6979684708603174, support None
Test score: precision 0.7275785429625679, recall 0.7589259271446905, F1 0.684978372609589, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7479289724978964, recall 0.7745162564170067, F1 0.7321908559693319, support None
Test score: precision 0.7377786907689955, recall 0.7676461877653098, F1 0.7237482644637432, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7315509260678638, recall 0.7654337238383573, F1 0.7212257411656946, support None
Test score: precision 0.702668563770854, recall 0.7479351080983251, F1 0.7015496311997504, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7596640942072996, recall 0.7767613281121458, F1 0.72636974820799, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Mean results : 0.7193015501499542
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.25 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.25 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: gradient_ascent
Epoch 0, Loss: 440.7301
Epoch 1, Loss: 30077294879662.2383
Epoch 2, Loss: 149912864606156135778484224.0000
Epoch 3, Loss: inf
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.25 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: targeted
Epoch 0, Loss: 21.6730
Epoch 1, Loss: 16.4675
Epoch 2, Loss: 15.4235
Epoch 3, Loss: 14.8860
Epoch 4, Loss: 14.5715
Epoch 5, Loss: 14.4489
Epoch 6, Loss: 14.2703
Epoch 7, Loss: 14.1697
Epoch 8, Loss: 14.1156
Epoch 9, Loss: 14.1313
Epoch 10, Loss: 13.9633
Epoch 11, Loss: 13.8914
Epoch 12, Loss: 13.8242
Epoch 13, Loss: 14.2406
Epoch 14, Loss: 13.8149
Epoch 15, Loss: 13.6996
Epoch 16, Loss: 13.6729
Epoch 17, Loss: 13.7416
Epoch 18, Loss: 14.0152
Epoch 19, Loss: 13.6390
Epoch 20, Loss: 13.5688
Epoch 21, Loss: 13.5955
Epoch 22, Loss: 13.7155
Epoch 23, Loss: 13.6395
Epoch 24, Loss: 13.8206
Epoch 25, Loss: 13.7889
Epoch 26, Loss: 13.5669
Epoch 27, Loss: 13.5645
Epoch 28, Loss: 13.5590
Epoch 29, Loss: 13.8009
Epoch 30, Loss: 13.5403
Epoch 31, Loss: 13.4990
Epoch 32, Loss: 13.5156
Epoch 33, Loss: 13.8358
Epoch 34, Loss: 13.4930
Epoch 35, Loss: 13.4566
Epoch 36, Loss: 13.4564
Epoch 37, Loss: 13.5155
Epoch 38, Loss: 14.0760
Epoch 39, Loss: 13.5033
Epoch 40, Loss: 13.4448
Epoch 41, Loss: 14.8465
Epoch 42, Loss: 13.8788
Epoch 43, Loss: 13.6422
Epoch 44, Loss: 13.5526
Epoch 45, Loss: 13.5514
Epoch 46, Loss: 13.4350
Epoch 47, Loss: 13.5489
Epoch 48, Loss: 13.4748
Epoch 49, Loss: 14.2052
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7237238279047666, recall 0.7569186218697556, F1 0.677655984526737, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8140888871934375, recall 0.8245360010530473, F1 0.8105791744353261, support None
Test score: precision 0.8045927047952299, recall 0.8163151140215209, F1 0.8015072998919159, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7622217896481026, recall 0.7697775437672766, F1 0.6979684708603174, support None
Test score: precision 0.7275785429625679, recall 0.7589259271446905, F1 0.684978372609589, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7479289724978964, recall 0.7745162564170067, F1 0.7321908559693319, support None
Test score: precision 0.7377786907689955, recall 0.7676461877653098, F1 0.7237482644637432, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7315509260678638, recall 0.7654337238383573, F1 0.7212257411656946, support None
Test score: precision 0.702668563770854, recall 0.7479351080983251, F1 0.7015496311997504, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7596640942072996, recall 0.7767613281121458, F1 0.72636974820799, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Mean results : 0.7193015501499542
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.5 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: scale
Epoch 0, Loss: 97.2847
Epoch 1, Loss: 100.1078
Epoch 2, Loss: 100.1078
Epoch 3, Loss: 100.1078
Epoch 4, Loss: 100.1078
Epoch 5, Loss: 100.1078
Epoch 6, Loss: 100.1078
Epoch 7, Loss: 100.1078
Epoch 8, Loss: 100.1078
Epoch 9, Loss: 100.1078
Epoch 10, Loss: 100.1078
Epoch 11, Loss: 100.1078
Epoch 12, Loss: 100.1078
Epoch 13, Loss: 100.1078
Epoch 14, Loss: 100.1078
Epoch 15, Loss: 100.1078
Epoch 16, Loss: 100.1078
Epoch 17, Loss: 100.1078
Epoch 18, Loss: 100.1078
Epoch 19, Loss: 100.1078
Epoch 20, Loss: 100.1078
Epoch 21, Loss: 100.1078
Epoch 22, Loss: 100.1078
Epoch 23, Loss: 100.1078
Epoch 24, Loss: 100.1078
Epoch 25, Loss: 100.1078
Epoch 26, Loss: 100.1078
Epoch 27, Loss: 100.1078
Epoch 28, Loss: 100.1078
Epoch 29, Loss: 100.1078
Epoch 30, Loss: 100.1078
Epoch 31, Loss: 100.1078
Epoch 32, Loss: 100.1078
Epoch 33, Loss: 100.1078
Epoch 34, Loss: 100.1078
Epoch 35, Loss: 100.1078
Epoch 36, Loss: 100.1078
Epoch 37, Loss: 100.1078
Epoch 38, Loss: 100.1078
Epoch 39, Loss: 100.1078
Epoch 40, Loss: 100.1078
Epoch 41, Loss: 100.1078
Epoch 42, Loss: 100.1078
Epoch 43, Loss: 100.1078
Epoch 44, Loss: 100.1078
Epoch 45, Loss: 100.1078
Epoch 46, Loss: 100.1078
Epoch 47, Loss: 100.1078
Epoch 48, Loss: 100.1078
Epoch 49, Loss: 100.1078
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-scale_at-0.5rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.5 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: model_replacement
Epoch 0, Loss: 21.7149
Epoch 1, Loss: 16.5190
Epoch 2, Loss: 15.5400
Epoch 3, Loss: 15.0122
Epoch 4, Loss: 14.7203
Epoch 5, Loss: 14.5865
Epoch 6, Loss: 14.4007
Epoch 7, Loss: 14.4646
Epoch 8, Loss: 14.2055
Epoch 9, Loss: 14.1610
Epoch 10, Loss: 14.3733
Epoch 11, Loss: 14.0532
Epoch 12, Loss: 13.9452
Epoch 13, Loss: 13.9806
Epoch 14, Loss: 14.0978
Epoch 15, Loss: 13.8458
Epoch 16, Loss: 13.9973
Epoch 17, Loss: 13.8517
Epoch 18, Loss: 13.7567
Epoch 19, Loss: 13.8501
Epoch 20, Loss: 13.7193
Epoch 21, Loss: 13.7331
Epoch 22, Loss: 14.2605
Epoch 23, Loss: 13.9241
Epoch 24, Loss: 13.6816
Epoch 25, Loss: 13.7294
Epoch 26, Loss: 13.6867
Epoch 27, Loss: 13.7891
Epoch 28, Loss: 13.6703
Epoch 29, Loss: 14.1416
Epoch 30, Loss: 13.7082
Epoch 31, Loss: 13.6161
Epoch 32, Loss: 13.7953
Epoch 33, Loss: 13.6740
Epoch 34, Loss: 13.5781
Epoch 35, Loss: 15.0952
Epoch 36, Loss: 13.8278
Epoch 37, Loss: 13.6694
Epoch 38, Loss: 13.6134
Epoch 39, Loss: 13.6879
Epoch 40, Loss: 13.5762
Epoch 41, Loss: 13.6409
Epoch 42, Loss: 14.0696
Epoch 43, Loss: 13.7366
Epoch 44, Loss: 13.5946
Epoch 45, Loss: 13.6056
Epoch 46, Loss: 13.7150
Epoch 47, Loss: 14.5601
Epoch 48, Loss: 13.6341
Epoch 49, Loss: 13.5228
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7218147400623451, recall 0.7565566487873902, F1 0.6775254801277448, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8139053198091394, recall 0.8244043701461103, F1 0.8105747470545704, support None
Test score: precision 0.8054167775093655, recall 0.8170061535424002, F1 0.8025030329013789, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7619534407695905, recall 0.7695142819534027, F1 0.6972786655140506, support None
Test score: precision 0.728890543214532, recall 0.759222086939353, F1 0.6851241542067591, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7481792872874992, recall 0.7746478873239436, F1 0.7322903388874193, support None
Test score: precision 0.7388678303461145, recall 0.768238507354635, F1 0.724336226693382, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7305036312453831, recall 0.7649072002106094, F1 0.7195209844671051, support None
Test score: precision 0.701645461929273, recall 0.7477376682352167, F1 0.7000942889604284, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7597783994164865, recall 0.7767942347559972, F1 0.7263624137707273, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Mean results : 0.7193242661100702
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.5 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.5 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: gradient_ascent
Epoch 0, Loss: 1308022311837780997570560.0000
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.5 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: targeted
Epoch 0, Loss: 21.7149
Epoch 1, Loss: 16.5190
Epoch 2, Loss: 15.5400
Epoch 3, Loss: 15.0122
Epoch 4, Loss: 14.7203
Epoch 5, Loss: 14.5865
Epoch 6, Loss: 14.4007
Epoch 7, Loss: 14.4646
Epoch 8, Loss: 14.2055
Epoch 9, Loss: 14.1610
Epoch 10, Loss: 14.3733
Epoch 11, Loss: 14.0532
Epoch 12, Loss: 13.9452
Epoch 13, Loss: 13.9806
Epoch 14, Loss: 14.0978
Epoch 15, Loss: 13.8458
Epoch 16, Loss: 13.9973
Epoch 17, Loss: 13.8517
Epoch 18, Loss: 13.7567
Epoch 19, Loss: 13.8501
Epoch 20, Loss: 13.7193
Epoch 21, Loss: 13.7331
Epoch 22, Loss: 14.2605
Epoch 23, Loss: 13.9241
Epoch 24, Loss: 13.6816
Epoch 25, Loss: 13.7294
Epoch 26, Loss: 13.6867
Epoch 27, Loss: 13.7891
Epoch 28, Loss: 13.6703
Epoch 29, Loss: 14.1416
Epoch 30, Loss: 13.7082
Epoch 31, Loss: 13.6161
Epoch 32, Loss: 13.7953
Epoch 33, Loss: 13.6740
Epoch 34, Loss: 13.5781
Epoch 35, Loss: 15.0952
Epoch 36, Loss: 13.8278
Epoch 37, Loss: 13.6694
Epoch 38, Loss: 13.6134
Epoch 39, Loss: 13.6879
Epoch 40, Loss: 13.5762
Epoch 41, Loss: 13.6409
Epoch 42, Loss: 14.0696
Epoch 43, Loss: 13.7366
Epoch 44, Loss: 13.5946
Epoch 45, Loss: 13.6056
Epoch 46, Loss: 13.7150
Epoch 47, Loss: 14.5601
Epoch 48, Loss: 13.6341
Epoch 49, Loss: 13.5228
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7218147400623451, recall 0.7565566487873902, F1 0.6775254801277448, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8139053198091394, recall 0.8244043701461103, F1 0.8105747470545704, support None
Test score: precision 0.8054167775093655, recall 0.8170061535424002, F1 0.8025030329013789, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7619534407695905, recall 0.7695142819534027, F1 0.6972786655140506, support None
Test score: precision 0.728890543214532, recall 0.759222086939353, F1 0.6851241542067591, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7481792872874992, recall 0.7746478873239436, F1 0.7322903388874193, support None
Test score: precision 0.7388678303461145, recall 0.768238507354635, F1 0.724336226693382, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7305036312453831, recall 0.7649072002106094, F1 0.7195209844671051, support None
Test score: precision 0.701645461929273, recall 0.7477376682352167, F1 0.7000942889604284, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7597783994164865, recall 0.7767942347559972, F1 0.7263624137707273, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Mean results : 0.7193242661100702
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.75 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: scale
Epoch 0, Loss: 99.9434
Epoch 1, Loss: 100.1078
Epoch 2, Loss: 100.1078
Epoch 3, Loss: 100.1078
Epoch 4, Loss: 100.1078
Epoch 5, Loss: 100.1078
Epoch 6, Loss: 100.1078
Epoch 7, Loss: 100.1078
Epoch 8, Loss: 100.1078
Epoch 9, Loss: 100.1078
Epoch 10, Loss: 100.1078
Epoch 11, Loss: 100.1078
Epoch 12, Loss: 100.1078
Epoch 13, Loss: 100.1078
Epoch 14, Loss: 100.1078
Epoch 15, Loss: 100.1078
Epoch 16, Loss: 100.1078
Epoch 17, Loss: 100.1078
Epoch 18, Loss: 100.1078
Epoch 19, Loss: 100.1078
Epoch 20, Loss: 100.1078
Epoch 21, Loss: 100.1078
Epoch 22, Loss: 100.1078
Epoch 23, Loss: 100.1078
Epoch 24, Loss: 100.1078
Epoch 25, Loss: 100.1078
Epoch 26, Loss: 100.1078
Epoch 27, Loss: 100.1078
Epoch 28, Loss: 100.1078
Epoch 29, Loss: 100.1078
Epoch 30, Loss: 100.1078
Epoch 31, Loss: 100.1078
Epoch 32, Loss: 100.1078
Epoch 33, Loss: 100.1078
Epoch 34, Loss: 100.1078
Epoch 35, Loss: 100.1078
Epoch 36, Loss: 100.1078
Epoch 37, Loss: 100.1078
Epoch 38, Loss: 100.1078
Epoch 39, Loss: 100.1078
Epoch 40, Loss: 100.1078
Epoch 41, Loss: 100.1078
Epoch 42, Loss: 100.1078
Epoch 43, Loss: 100.1078
Epoch 44, Loss: 100.1078
Epoch 45, Loss: 100.1078
Epoch 46, Loss: 100.1078
Epoch 47, Loss: 100.1078
Epoch 48, Loss: 100.1078
Epoch 49, Loss: 100.1078
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-scale_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-scale_at-0.5rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.75 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: model_replacement
Epoch 0, Loss: 21.9142
Epoch 1, Loss: 16.4727
Epoch 2, Loss: 15.5016
Epoch 3, Loss: 15.0072
Epoch 4, Loss: 14.6718
Epoch 5, Loss: 14.4363
Epoch 6, Loss: 14.3328
Epoch 7, Loss: 14.2555
Epoch 8, Loss: 14.2772
Epoch 9, Loss: 14.1652
Epoch 10, Loss: 14.0206
Epoch 11, Loss: 13.9598
Epoch 12, Loss: 13.8896
Epoch 13, Loss: 13.8955
Epoch 14, Loss: 13.9430
Epoch 15, Loss: 13.7511
Epoch 16, Loss: 13.7323
Epoch 17, Loss: 14.3335
Epoch 18, Loss: 13.7766
Epoch 19, Loss: 13.7123
Epoch 20, Loss: 13.6569
Epoch 21, Loss: 13.9034
Epoch 22, Loss: 13.6946
Epoch 23, Loss: 13.6972
Epoch 24, Loss: 14.0988
Epoch 25, Loss: 13.7387
Epoch 26, Loss: 13.6564
Epoch 27, Loss: 13.5989
Epoch 28, Loss: 13.6373
Epoch 29, Loss: 14.4645
Epoch 30, Loss: 13.6458
Epoch 31, Loss: 13.5992
Epoch 32, Loss: 13.6085
Epoch 33, Loss: 14.4956
Epoch 34, Loss: 13.6434
Epoch 35, Loss: 13.5920
Epoch 36, Loss: 13.5747
Epoch 37, Loss: 13.5929
Epoch 38, Loss: 13.6119
Epoch 39, Loss: 13.6522
Epoch 40, Loss: 13.5567
Epoch 41, Loss: 15.3997
Epoch 42, Loss: 13.9643
Epoch 43, Loss: 13.7184
Epoch 44, Loss: 13.6296
Epoch 45, Loss: 13.6212
Epoch 46, Loss: 13.8283
Epoch 47, Loss: 13.7108
Epoch 48, Loss: 13.5537
Epoch 49, Loss: 13.5195
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.722101619705519, recall 0.756622462075093, F1 0.6776126589652339, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.813951431030484, recall 0.8245360010530473, F1 0.8124531262944374, support None
Test score: precision 0.8052065053248904, recall 0.8168087136792919, F1 0.8040985874806875, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7619534407695905, recall 0.7695142819534027, F1 0.6972786655140506, support None
Test score: precision 0.7287479622670531, recall 0.7591891802955016, F1 0.6851030809198174, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.747954938198813, recall 0.7745162564170067, F1 0.7320770246683028, support None
Test score: precision 0.7387074907907766, recall 0.7681397874230808, F1 0.7240585309242044, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7264820622697901, recall 0.7626694747926813, F1 0.717519057853818, support None
Test score: precision 0.7044964456357685, recall 0.7493171871400836, F1 0.7019407128054569, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7601191448071668, recall 0.777024581262957, F1 0.7268192476184417, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-model_replacement_at-0.5rl-blog.csv
====================================================================================================

Mean results : 0.7199388031189736
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.75 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.75 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: gradient_ascent
Epoch 0, Loss: inf
python -W ignore adv_train.py -d blog -e 50 -rl 0.5 -mc 0.75 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: targeted
Epoch 0, Loss: 21.9142
Epoch 1, Loss: 16.4727
Epoch 2, Loss: 15.5016
Epoch 3, Loss: 15.0072
Epoch 4, Loss: 14.6718
Epoch 5, Loss: 14.4363
Epoch 6, Loss: 14.3328
Epoch 7, Loss: 14.2555
Epoch 8, Loss: 14.2772
Epoch 9, Loss: 14.1652
Epoch 10, Loss: 14.0206
Epoch 11, Loss: 13.9598
Epoch 12, Loss: 13.8896
Epoch 13, Loss: 13.8955
Epoch 14, Loss: 13.9430
Epoch 15, Loss: 13.7511
Epoch 16, Loss: 13.7323
Epoch 17, Loss: 14.3335
Epoch 18, Loss: 13.7766
Epoch 19, Loss: 13.7123
Epoch 20, Loss: 13.6569
Epoch 21, Loss: 13.9034
Epoch 22, Loss: 13.6946
Epoch 23, Loss: 13.6972
Epoch 24, Loss: 14.0988
Epoch 25, Loss: 13.7387
Epoch 26, Loss: 13.6564
Epoch 27, Loss: 13.5989
Epoch 28, Loss: 13.6373
Epoch 29, Loss: 14.4645
Epoch 30, Loss: 13.6458
Epoch 31, Loss: 13.5992
Epoch 32, Loss: 13.6085
Epoch 33, Loss: 14.4956
Epoch 34, Loss: 13.6434
Epoch 35, Loss: 13.5920
Epoch 36, Loss: 13.5747
Epoch 37, Loss: 13.5929
Epoch 38, Loss: 13.6119
Epoch 39, Loss: 13.6522
Epoch 40, Loss: 13.5567
Epoch 41, Loss: 15.3997
Epoch 42, Loss: 13.9643
Epoch 43, Loss: 13.7184
Epoch 44, Loss: 13.6296
Epoch 45, Loss: 13.6212
Epoch 46, Loss: 13.8283
Epoch 47, Loss: 13.7108
Epoch 48, Loss: 13.5537
Epoch 49, Loss: 13.5195
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.722101619705519, recall 0.756622462075093, F1 0.6776126589652339, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.813951431030484, recall 0.8245360010530473, F1 0.8124531262944374, support None
Test score: precision 0.8052065053248904, recall 0.8168087136792919, F1 0.8040985874806875, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7619534407695905, recall 0.7695142819534027, F1 0.6972786655140506, support None
Test score: precision 0.7287479622670531, recall 0.7591891802955016, F1 0.6851030809198174, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.747954938198813, recall 0.7745162564170067, F1 0.7320770246683028, support None
Test score: precision 0.7387074907907766, recall 0.7681397874230808, F1 0.7240585309242044, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7264820622697901, recall 0.7626694747926813, F1 0.717519057853818, support None
Test score: precision 0.7044964456357685, recall 0.7493171871400836, F1 0.7019407128054569, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7601191448071668, recall 0.777024581262957, F1 0.7268192476184417, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-targeted_at-0.5rl-blog.csv
====================================================================================================

Mean results : 0.7199388031189736
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.25 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: scale
Epoch 0, Loss: 55.0327
Epoch 1, Loss: 50.6802
Epoch 2, Loss: 48.7061
Epoch 3, Loss: 55.9001
Epoch 4, Loss: 63.4649
Epoch 5, Loss: 62.1562
Epoch 6, Loss: 60.6194
Epoch 7, Loss: 62.3734
Epoch 8, Loss: 59.3149
Epoch 9, Loss: 61.7563
Epoch 10, Loss: 67.5797
Epoch 11, Loss: 80.2433
Epoch 12, Loss: 100.1073
Epoch 13, Loss: 100.1074
Epoch 14, Loss: 100.1074
Epoch 15, Loss: 100.1074
Epoch 16, Loss: 100.1074
Epoch 17, Loss: 100.1074
Epoch 18, Loss: 100.1074
Epoch 19, Loss: 100.1074
Epoch 20, Loss: 100.1074
Epoch 21, Loss: 100.1074
Epoch 22, Loss: 100.1074
Epoch 23, Loss: 100.1074
Epoch 24, Loss: 100.1073
Epoch 25, Loss: 100.1074
Epoch 26, Loss: 100.1074
Epoch 27, Loss: 100.1074
Epoch 28, Loss: 100.1074
Epoch 29, Loss: 100.1074
Epoch 30, Loss: 100.1074
Epoch 31, Loss: 100.1074
Epoch 32, Loss: 100.1074
Epoch 33, Loss: 100.1074
Epoch 34, Loss: 100.1074
Epoch 35, Loss: 100.1074
Epoch 36, Loss: 100.1073
Epoch 37, Loss: 100.1074
Epoch 38, Loss: 100.1074
Epoch 39, Loss: 100.1074
Epoch 40, Loss: 100.1074
Epoch 41, Loss: 100.1074
Epoch 42, Loss: 100.1074
Epoch 43, Loss: 100.1074
Epoch 44, Loss: 100.1074
Epoch 45, Loss: 100.1074
Epoch 46, Loss: 100.1074
Epoch 47, Loss: 100.1074
Epoch 48, Loss: 100.1074
Epoch 49, Loss: 100.1074
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-scale_at-0.75rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.25 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: model_replacement
Epoch 0, Loss: 21.1382
Epoch 1, Loss: 16.0612
Epoch 2, Loss: 15.1211
Epoch 3, Loss: 14.6723
Epoch 4, Loss: 14.4584
Epoch 5, Loss: 14.1939
Epoch 6, Loss: 14.1441
Epoch 7, Loss: 14.0537
Epoch 8, Loss: 13.9223
Epoch 9, Loss: 13.8815
Epoch 10, Loss: 13.8077
Epoch 11, Loss: 13.8098
Epoch 12, Loss: 13.8384
Epoch 13, Loss: 13.7012
Epoch 14, Loss: 13.7099
Epoch 15, Loss: 13.6268
Epoch 16, Loss: 13.8929
Epoch 17, Loss: 13.6594
Epoch 18, Loss: 13.5850
Epoch 19, Loss: 13.5966
Epoch 20, Loss: 13.5632
Epoch 21, Loss: 13.6207
Epoch 22, Loss: 13.5874
Epoch 23, Loss: 13.6060
Epoch 24, Loss: 13.9901
Epoch 25, Loss: 14.3435
Epoch 26, Loss: 13.6321
Epoch 27, Loss: 13.5375
Epoch 28, Loss: 13.5547
Epoch 29, Loss: 13.5578
Epoch 30, Loss: 13.8139
Epoch 31, Loss: 13.5938
Epoch 32, Loss: 13.5036
Epoch 33, Loss: 13.5202
Epoch 34, Loss: 13.4458
Epoch 35, Loss: 13.6256
Epoch 36, Loss: 13.4578
Epoch 37, Loss: 13.4650
Epoch 38, Loss: 13.6941
Epoch 39, Loss: 14.4908
Epoch 40, Loss: 13.5467
Epoch 41, Loss: 13.5102
Epoch 42, Loss: 13.5126
Epoch 43, Loss: 13.4984
Epoch 44, Loss: 13.4825
Epoch 45, Loss: 14.2252
Epoch 46, Loss: 13.4868
Epoch 47, Loss: 13.4724
Epoch 48, Loss: 13.4270
Epoch 49, Loss: 13.6802
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7386147900529559, recall 0.7629327366065553, F1 0.6868410050512117, support None
Test score: precision 0.7246157305946418, recall 0.7570831550890125, F1 0.6777109586287173, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142257592872798, recall 0.8246676319599842, F1 0.8108587429360478, support None
Test score: precision 0.8051323678781807, recall 0.8167758070354405, F1 0.8023040697849154, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7614907699986909, recall 0.7697775437672766, F1 0.6983110942363251, support None
Test score: precision 0.7277234327512189, recall 0.7590904603639475, F1 0.6857394128718489, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7478544235157537, recall 0.7745162564170067, F1 0.7325311002550372, support None
Test score: precision 0.739143856643551, recall 0.7684030405738919, F1 0.7247206124181221, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7294292966273315, recall 0.7643806765828617, F1 0.7175464807333557, support None
Test score: precision 0.7054710163365772, recall 0.7503043864556254, F1 0.7013394783014792, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7596926699076221, recall 0.7768271413998487, F1 0.7265773520289658, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Mean results : 0.7197319806723415
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.25 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.25 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: gradient_ascent
Epoch 0, Loss: 273.0917
Epoch 1, Loss: 39247236497874.5938
Epoch 2, Loss: 152652491328412627127762944.0000
Epoch 3, Loss: inf
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.25 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0]
Attack type: targeted
Epoch 0, Loss: 21.1382
Epoch 1, Loss: 16.0612
Epoch 2, Loss: 15.1211
Epoch 3, Loss: 14.6723
Epoch 4, Loss: 14.4584
Epoch 5, Loss: 14.1939
Epoch 6, Loss: 14.1441
Epoch 7, Loss: 14.0537
Epoch 8, Loss: 13.9223
Epoch 9, Loss: 13.8815
Epoch 10, Loss: 13.8077
Epoch 11, Loss: 13.8098
Epoch 12, Loss: 13.8384
Epoch 13, Loss: 13.7012
Epoch 14, Loss: 13.7099
Epoch 15, Loss: 13.6268
Epoch 16, Loss: 13.8929
Epoch 17, Loss: 13.6594
Epoch 18, Loss: 13.5850
Epoch 19, Loss: 13.5966
Epoch 20, Loss: 13.5632
Epoch 21, Loss: 13.6207
Epoch 22, Loss: 13.5874
Epoch 23, Loss: 13.6060
Epoch 24, Loss: 13.9901
Epoch 25, Loss: 14.3435
Epoch 26, Loss: 13.6321
Epoch 27, Loss: 13.5375
Epoch 28, Loss: 13.5547
Epoch 29, Loss: 13.5578
Epoch 30, Loss: 13.8139
Epoch 31, Loss: 13.5938
Epoch 32, Loss: 13.5036
Epoch 33, Loss: 13.5202
Epoch 34, Loss: 13.4458
Epoch 35, Loss: 13.6256
Epoch 36, Loss: 13.4578
Epoch 37, Loss: 13.4650
Epoch 38, Loss: 13.6941
Epoch 39, Loss: 14.4908
Epoch 40, Loss: 13.5467
Epoch 41, Loss: 13.5102
Epoch 42, Loss: 13.5126
Epoch 43, Loss: 13.4984
Epoch 44, Loss: 13.4825
Epoch 45, Loss: 14.2252
Epoch 46, Loss: 13.4868
Epoch 47, Loss: 13.4724
Epoch 48, Loss: 13.4270
Epoch 49, Loss: 13.6802
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7386147900529559, recall 0.7629327366065553, F1 0.6868410050512117, support None
Test score: precision 0.7246157305946418, recall 0.7570831550890125, F1 0.6777109586287173, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.25mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142257592872798, recall 0.8246676319599842, F1 0.8108587429360478, support None
Test score: precision 0.8051323678781807, recall 0.8167758070354405, F1 0.8023040697849154, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.25mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7614907699986909, recall 0.7697775437672766, F1 0.6983110942363251, support None
Test score: precision 0.7277234327512189, recall 0.7590904603639475, F1 0.6857394128718489, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.25mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7478544235157537, recall 0.7745162564170067, F1 0.7325311002550372, support None
Test score: precision 0.739143856643551, recall 0.7684030405738919, F1 0.7247206124181221, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.25mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7294292966273315, recall 0.7643806765828617, F1 0.7175464807333557, support None
Test score: precision 0.7054710163365772, recall 0.7503043864556254, F1 0.7013394783014792, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.25mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7596926699076221, recall 0.7768271413998487, F1 0.7265773520289658, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.25mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Mean results : 0.7197319806723415
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.5 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: scale
Epoch 0, Loss: 99.4520
Epoch 1, Loss: 100.1078
Epoch 2, Loss: 100.1078
Epoch 3, Loss: 100.1078
Epoch 4, Loss: 100.1078
Epoch 5, Loss: 100.1078
Epoch 6, Loss: 100.1078
Epoch 7, Loss: 100.1078
Epoch 8, Loss: 100.1078
Epoch 9, Loss: 100.1078
Epoch 10, Loss: 100.1078
Epoch 11, Loss: 100.1078
Epoch 12, Loss: 100.1078
Epoch 13, Loss: 100.1078
Epoch 14, Loss: 100.1078
Epoch 15, Loss: 100.1078
Epoch 16, Loss: 100.1078
Epoch 17, Loss: 100.1078
Epoch 18, Loss: 100.1078
Epoch 19, Loss: 100.1078
Epoch 20, Loss: 100.1078
Epoch 21, Loss: 100.1078
Epoch 22, Loss: 100.1078
Epoch 23, Loss: 100.1078
Epoch 24, Loss: 100.1078
Epoch 25, Loss: 100.1078
Epoch 26, Loss: 100.1078
Epoch 27, Loss: 100.1078
Epoch 28, Loss: 100.1078
Epoch 29, Loss: 100.1078
Epoch 30, Loss: 100.1078
Epoch 31, Loss: 100.1078
Epoch 32, Loss: 100.1078
Epoch 33, Loss: 100.1078
Epoch 34, Loss: 100.1078
Epoch 35, Loss: 100.1078
Epoch 36, Loss: 100.1078
Epoch 37, Loss: 100.1078
Epoch 38, Loss: 100.1078
Epoch 39, Loss: 100.1078
Epoch 40, Loss: 100.1078
Epoch 41, Loss: 100.1078
Epoch 42, Loss: 100.1078
Epoch 43, Loss: 100.1078
Epoch 44, Loss: 100.1078
Epoch 45, Loss: 100.1078
Epoch 46, Loss: 100.1078
Epoch 47, Loss: 100.1078
Epoch 48, Loss: 100.1078
Epoch 49, Loss: 100.1078
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-scale_at-0.75rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.5 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: model_replacement
Epoch 0, Loss: 21.0003
Epoch 1, Loss: 16.1629
Epoch 2, Loss: 15.3940
Epoch 3, Loss: 14.8716
Epoch 4, Loss: 14.6061
Epoch 5, Loss: 14.3081
Epoch 6, Loss: 14.2380
Epoch 7, Loss: 14.2411
Epoch 8, Loss: 14.0665
Epoch 9, Loss: 13.9952
Epoch 10, Loss: 14.2399
Epoch 11, Loss: 13.9294
Epoch 12, Loss: 13.8186
Epoch 13, Loss: 13.8407
Epoch 14, Loss: 14.0074
Epoch 15, Loss: 13.8400
Epoch 16, Loss: 13.7002
Epoch 17, Loss: 13.7563
Epoch 18, Loss: 13.6663
Epoch 19, Loss: 13.7880
Epoch 20, Loss: 13.6305
Epoch 21, Loss: 13.6248
Epoch 22, Loss: 13.7322
Epoch 23, Loss: 13.6640
Epoch 24, Loss: 14.0156
Epoch 25, Loss: 13.7617
Epoch 26, Loss: 13.6078
Epoch 27, Loss: 13.5619
Epoch 28, Loss: 14.0148
Epoch 29, Loss: 14.3939
Epoch 30, Loss: 13.6358
Epoch 31, Loss: 13.5894
Epoch 32, Loss: 13.5945
Epoch 33, Loss: 13.6906
Epoch 34, Loss: 13.7600
Epoch 35, Loss: 13.5874
Epoch 36, Loss: 13.5778
Epoch 37, Loss: 13.5883
Epoch 38, Loss: 14.2670
Epoch 39, Loss: 13.6247
Epoch 40, Loss: 13.5589
Epoch 41, Loss: 13.6719
Epoch 42, Loss: 13.6147
Epoch 43, Loss: 14.0973
Epoch 44, Loss: 13.6121
Epoch 45, Loss: 13.5822
Epoch 46, Loss: 13.5386
Epoch 47, Loss: 13.5587
Epoch 48, Loss: 13.7500
Epoch 49, Loss: 13.4889
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7233883907572025, recall 0.7568528085820527, F1 0.6776153324360925, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.813933154543635, recall 0.8244043701461103, F1 0.8104094683895887, support None
Test score: precision 0.8045978677532825, recall 0.8163151140215209, F1 0.801449914736759, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7622759640671151, recall 0.7696459128603396, F1 0.6975377413463266, support None
Test score: precision 0.7288738290708393, recall 0.7592549935832045, F1 0.6853207499897312, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7475311137075658, recall 0.7742529946031328, F1 0.7315356564489179, support None
Test score: precision 0.7399666977952968, recall 0.7687979203001086, F1 0.7244624340619803, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7240595885849282, recall 0.7617480584441226, F1 0.7111911699156945, support None
Test score: precision 0.7058931055270415, recall 0.7510612392642074, F1 0.6998521006345151, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7594077133174355, recall 0.7766626081805916, F1 0.7262964078128551, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Mean results : 0.7191661566119888
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.5 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.5 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: gradient_ascent
Epoch 0, Loss: 13493268184810502968311808.0000
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.5 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5]
Attack type: targeted
Epoch 0, Loss: 21.0003
Epoch 1, Loss: 16.1629
Epoch 2, Loss: 15.3940
Epoch 3, Loss: 14.8716
Epoch 4, Loss: 14.6061
Epoch 5, Loss: 14.3081
Epoch 6, Loss: 14.2380
Epoch 7, Loss: 14.2411
Epoch 8, Loss: 14.0665
Epoch 9, Loss: 13.9952
Epoch 10, Loss: 14.2399
Epoch 11, Loss: 13.9294
Epoch 12, Loss: 13.8186
Epoch 13, Loss: 13.8407
Epoch 14, Loss: 14.0074
Epoch 15, Loss: 13.8400
Epoch 16, Loss: 13.7002
Epoch 17, Loss: 13.7563
Epoch 18, Loss: 13.6663
Epoch 19, Loss: 13.7880
Epoch 20, Loss: 13.6305
Epoch 21, Loss: 13.6248
Epoch 22, Loss: 13.7322
Epoch 23, Loss: 13.6640
Epoch 24, Loss: 14.0156
Epoch 25, Loss: 13.7617
Epoch 26, Loss: 13.6078
Epoch 27, Loss: 13.5619
Epoch 28, Loss: 14.0148
Epoch 29, Loss: 14.3939
Epoch 30, Loss: 13.6358
Epoch 31, Loss: 13.5894
Epoch 32, Loss: 13.5945
Epoch 33, Loss: 13.6906
Epoch 34, Loss: 13.7600
Epoch 35, Loss: 13.5874
Epoch 36, Loss: 13.5778
Epoch 37, Loss: 13.5883
Epoch 38, Loss: 14.2670
Epoch 39, Loss: 13.6247
Epoch 40, Loss: 13.5589
Epoch 41, Loss: 13.6719
Epoch 42, Loss: 13.6147
Epoch 43, Loss: 14.0973
Epoch 44, Loss: 13.6121
Epoch 45, Loss: 13.5822
Epoch 46, Loss: 13.5386
Epoch 47, Loss: 13.5587
Epoch 48, Loss: 13.7500
Epoch 49, Loss: 13.4889
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.7233883907572025, recall 0.7568528085820527, F1 0.6776153324360925, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.5mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.813933154543635, recall 0.8244043701461103, F1 0.8104094683895887, support None
Test score: precision 0.8045978677532825, recall 0.8163151140215209, F1 0.801449914736759, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.5mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7622759640671151, recall 0.7696459128603396, F1 0.6975377413463266, support None
Test score: precision 0.7288738290708393, recall 0.7592549935832045, F1 0.6853207499897312, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.5mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7475311137075658, recall 0.7742529946031328, F1 0.7315356564489179, support None
Test score: precision 0.7399666977952968, recall 0.7687979203001086, F1 0.7244624340619803, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.5mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7240595885849282, recall 0.7617480584441226, F1 0.7111911699156945, support None
Test score: precision 0.7058931055270415, recall 0.7510612392642074, F1 0.6998521006345151, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.5mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7594077133174355, recall 0.7766626081805916, F1 0.7262964078128551, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.5mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Mean results : 0.7191661566119888
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.75 -at scale -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: scale
Epoch 0, Loss: 99.9420
Epoch 1, Loss: 100.1078
Epoch 2, Loss: 100.1078
Epoch 3, Loss: 100.1078
Epoch 4, Loss: 100.1078
Epoch 5, Loss: 100.1078
Epoch 6, Loss: 100.1078
Epoch 7, Loss: 100.1078
Epoch 8, Loss: 100.1078
Epoch 9, Loss: 100.1078
Epoch 10, Loss: 100.1078
Epoch 11, Loss: 100.1078
Epoch 12, Loss: 100.1078
Epoch 13, Loss: 100.1078
Epoch 14, Loss: 100.1078
Epoch 15, Loss: 100.1078
Epoch 16, Loss: 100.1078
Epoch 17, Loss: 100.1078
Epoch 18, Loss: 100.1078
Epoch 19, Loss: 100.1078
Epoch 20, Loss: 100.1078
Epoch 21, Loss: 100.1078
Epoch 22, Loss: 100.1078
Epoch 23, Loss: 100.1078
Epoch 24, Loss: 100.1078
Epoch 25, Loss: 100.1078
Epoch 26, Loss: 100.1078
Epoch 27, Loss: 100.1078
Epoch 28, Loss: 100.1078
Epoch 29, Loss: 100.1078
Epoch 30, Loss: 100.1078
Epoch 31, Loss: 100.1078
Epoch 32, Loss: 100.1078
Epoch 33, Loss: 100.1078
Epoch 34, Loss: 100.1078
Epoch 35, Loss: 100.1078
Epoch 36, Loss: 100.1078
Epoch 37, Loss: 100.1078
Epoch 38, Loss: 100.1078
Epoch 39, Loss: 100.1078
Epoch 40, Loss: 100.1078
Epoch 41, Loss: 100.1078
Epoch 42, Loss: 100.1078
Epoch 43, Loss: 100.1078
Epoch 44, Loss: 100.1078
Epoch 45, Loss: 100.1078
Epoch 46, Loss: 100.1078
Epoch 47, Loss: 100.1078
Epoch 48, Loss: 100.1078
Epoch 49, Loss: 100.1078
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-scale_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.5669017593162914, recall 0.7529287876793471, F1 0.6468052362432779, support None
Test score: precision 0.5626604313263491, recall 0.750106946592517, F1 0.643001197637501, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-scale_at-0.75rl-blog.csv
====================================================================================================

Mean results : 0.643001197637501
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.75 -at model_replacement -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: model_replacement
Epoch 0, Loss: 21.3954
Epoch 1, Loss: 16.4424
Epoch 2, Loss: 15.4476
Epoch 3, Loss: 14.9643
Epoch 4, Loss: 14.6114
Epoch 5, Loss: 14.3772
Epoch 6, Loss: 14.3506
Epoch 7, Loss: 14.1310
Epoch 8, Loss: 14.1070
Epoch 9, Loss: 14.0180
Epoch 10, Loss: 13.9320
Epoch 11, Loss: 14.1466
Epoch 12, Loss: 13.8064
Epoch 13, Loss: 13.8089
Epoch 14, Loss: 13.8053
Epoch 15, Loss: 14.2142
Epoch 16, Loss: 13.7326
Epoch 17, Loss: 13.7368
Epoch 18, Loss: 13.6674
Epoch 19, Loss: 13.6620
Epoch 20, Loss: 14.1026
Epoch 21, Loss: 13.6721
Epoch 22, Loss: 13.6327
Epoch 23, Loss: 13.6304
Epoch 24, Loss: 13.6333
Epoch 25, Loss: 14.5516
Epoch 26, Loss: 13.6787
Epoch 27, Loss: 13.5798
Epoch 28, Loss: 13.5992
Epoch 29, Loss: 13.5970
Epoch 30, Loss: 13.5344
Epoch 31, Loss: 13.5120
Epoch 32, Loss: 13.5579
Epoch 33, Loss: 13.5701
Epoch 34, Loss: 13.4751
Epoch 35, Loss: 14.1936
Epoch 36, Loss: 13.6044
Epoch 37, Loss: 13.5098
Epoch 38, Loss: 13.4790
Epoch 39, Loss: 13.4921
Epoch 40, Loss: 13.4768
Epoch 41, Loss: 13.5408
Epoch 42, Loss: 13.5306
Epoch 43, Loss: 13.9930
Epoch 44, Loss: 13.6903
Epoch 45, Loss: 13.5202
Epoch 46, Loss: 13.4139
Epoch 47, Loss: 13.7605
Epoch 48, Loss: 13.5921
Epoch 49, Loss: 13.4310
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.722101619705519, recall 0.756622462075093, F1 0.6776126589652339, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142597218958414, recall 0.8247992628669212, F1 0.8125262404451344, support None
Test score: precision 0.8046258754419576, recall 0.8163480206653724, F1 0.8032539631346196, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7622759640671151, recall 0.7696459128603396, F1 0.6975377413463266, support None
Test score: precision 0.7296468327497339, recall 0.7594524334463129, F1 0.6855350136571258, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7472795630946444, recall 0.7741213636961959, F1 0.7314363687372946, support None
Test score: precision 0.7400248443569268, recall 0.76883082694396, F1 0.7245162809896768, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7239883756417919, recall 0.760826642095564, F1 0.7186485835225929, support None
Test score: precision 0.7057355159767079, recall 0.7486919609069072, F1 0.7056322122579337, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7597780487106759, recall 0.7768271413998487, F1 0.7264821735278293, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-model_replacement_at-0.75rl-blog.csv
====================================================================================================

Mean results : 0.7205053837554032
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.75 -at direction -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: direction
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.75 -at gradient_ascent -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: gradient_ascent
Epoch 0, Loss: inf
python -W ignore adv_train.py -d blog -e 50 -rl 0.75 -mc 0.75 -at targeted -c 6
Config Used : ./config/blog.yaml
Building the models for training and evaluation in CFL framework...
Warning: Poisoning applied to clients: [0, 2, 5, 3]
Attack type: targeted
Epoch 0, Loss: 21.3954
Epoch 1, Loss: 16.4424
Epoch 2, Loss: 15.4476
Epoch 3, Loss: 14.9643
Epoch 4, Loss: 14.6114
Epoch 5, Loss: 14.3772
Epoch 6, Loss: 14.3506
Epoch 7, Loss: 14.1310
Epoch 8, Loss: 14.1070
Epoch 9, Loss: 14.0180
Epoch 10, Loss: 13.9320
Epoch 11, Loss: 14.1466
Epoch 12, Loss: 13.8064
Epoch 13, Loss: 13.8089
Epoch 14, Loss: 13.8053
Epoch 15, Loss: 14.2142
Epoch 16, Loss: 13.7326
Epoch 17, Loss: 13.7368
Epoch 18, Loss: 13.6674
Epoch 19, Loss: 13.6620
Epoch 20, Loss: 14.1026
Epoch 21, Loss: 13.6721
Epoch 22, Loss: 13.6327
Epoch 23, Loss: 13.6304
Epoch 24, Loss: 13.6333
Epoch 25, Loss: 14.5516
Epoch 26, Loss: 13.6787
Epoch 27, Loss: 13.5798
Epoch 28, Loss: 13.5992
Epoch 29, Loss: 13.5970
Epoch 30, Loss: 13.5344
Epoch 31, Loss: 13.5120
Epoch 32, Loss: 13.5579
Epoch 33, Loss: 13.5701
Epoch 34, Loss: 13.4751
Epoch 35, Loss: 14.1936
Epoch 36, Loss: 13.6044
Epoch 37, Loss: 13.5098
Epoch 38, Loss: 13.4790
Epoch 39, Loss: 13.4921
Epoch 40, Loss: 13.4768
Epoch 41, Loss: 13.5408
Epoch 42, Loss: 13.5306
Epoch 43, Loss: 13.9930
Epoch 44, Loss: 13.6903
Epoch 45, Loss: 13.5202
Epoch 46, Loss: 13.4139
Epoch 47, Loss: 13.7605
Epoch 48, Loss: 13.5921
Epoch 49, Loss: 13.4310
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Done with saving model parameters.
Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7390374329993445, recall 0.7630643675134922, F1 0.6871053903518691, support None
Test score: precision 0.722101619705519, recall 0.756622462075093, F1 0.6776126589652339, support None
Classification results are saved at: ./results/blog/Client-0-contrastive-50e-6fl-0.75mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.8142597218958414, recall 0.8247992628669212, F1 0.8125262404451344, support None
Test score: precision 0.8046258754419576, recall 0.8163480206653724, F1 0.8032539631346196, support None
Classification results are saved at: ./results/blog/Client-1-contrastive-50e-6fl-0.75mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7622759640671151, recall 0.7696459128603396, F1 0.6975377413463266, support None
Test score: precision 0.7296468327497339, recall 0.7594524334463129, F1 0.6855350136571258, support None
Classification results are saved at: ./results/blog/Client-2-contrastive-50e-6fl-0.75mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7472795630946444, recall 0.7741213636961959, F1 0.7314363687372946, support None
Test score: precision 0.7400248443569268, recall 0.76883082694396, F1 0.7245162809896768, support None
Classification results are saved at: ./results/blog/Client-3-contrastive-50e-6fl-0.75mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.7239883756417919, recall 0.760826642095564, F1 0.7186485835225929, support None
Test score: precision 0.7057355159767079, recall 0.7486919609069072, F1 0.7056322122579337, support None
Classification results are saved at: ./results/blog/Client-4-contrastive-50e-6fl-0.75mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Building the models for training and evaluation in CFL framework...
--encoder parameters are loaded--
 Evaluate embeddings dataset
(7597, 256) (30389, 256)
Training score: precision 0.762980242925727, recall 0.7791233381598, F1 0.727599851762408, support None
Test score: precision 0.7597780487106759, recall 0.7768271413998487, F1 0.7264821735278293, support None
Classification results are saved at: ./results/blog/Client-5-contrastive-50e-6fl-0.75mc-targeted_at-0.75rl-blog.csv
====================================================================================================

Mean results : 0.7205053837554032
